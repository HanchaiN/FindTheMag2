# DO NOT EDIT THIS FILE, EDIT USER_CONFIG.PY INSTEAD
# SPDX-License-Identifier: AGPL-3.0-only
from __future__ import annotations

__version__ = "3.3"


try:
    import copy
    import shlex
    import shutil
    import subprocess
    import functools
    from time import sleep
    import asyncio
    import logging.handlers
    import os
    import libs.pyboinc
    import json
    import re
    import platform
    import importlib
    from pathlib import Path
    import datetime
    import pprint
    from typing import List, Union, Dict, Tuple, Any, Callable, Collection
    import sys, signal
    from utils.grc_price_utils import get_grc_price_from_sites
    from utils.currency_utils import get_currency_from_sites
    from utils.StatsHelper import (
        add_mag_to_combined_stats,
        config_files_to_stats,
        get_highest_priority_project,
        get_most_mag_efficient_projects,
        resolve_url_boinc_rpc,
        get_avg_mag_hr,
    )
    from utils.BoincClientConnection import (
        BoincClientConnection,
        check_log_entries,
        check_log_entries_for_backoff,
        get_all_projects,
        get_attached_projects,
        get_task_list,
        is_boinc_crunching,
        kill_all_unstarted_tasks,
        nnt_all_projects,
        prefs_check,
        run_rpc_command,
        setup_connection,
        undo_nnt_all_projects,
        verify_boinc_connection,
        wait_till_no_xfers,
    )
    from utils.GridcoinClientConnection import (
        GridcoinClientConnection,
        wait_till_synced,
        get_gridcoin_config_parameters,
        ProjectMagRatio,
        check_sidestake,
    )
    from utils.utils import (
        GracefulInterruptHandler,
        center_align,
        combine_dicts,
        date_to_date,
        json_default,
        left_align,
        object_hook,
        print_and_log as _print_and_log,
        resolve_url_database,
        resolve_url_list_to_database,
        project_url_to_name,
        project_list_to_project_list,
    )

    # This is needed for some async stuff
    import nest_asyncio

    nest_asyncio.apply()

    # Ignore deprecation warnings in Windows
    import warnings
except Exception as e:
    print(
        "Error loading some required modules. Make sure you have installed the modules in requirements.txt as documented in the README"
    )
    print(str(e))
    import sys

    sys.exit(1)


warnings.filterwarnings("ignore", category=DeprecationWarning)

# Set default settings for all vars
PREFERRED_PROJECTS: Dict[str, float] = {}
PREFERRED_PROJECTS_PERCENT: float = 10
IGNORED_PROJECTS: List[str] = ["https://foldingathome.div72.xyz/"]

ONLY_BOINC_IF_PROFITABLE: bool = False
ONLY_MINE_IF_PROFITABLE: bool = False
CURRENCY_CODE: str = "USD"
LOCAL_KWH: float = 0.1542
GRC_SELL_PRICE: Union[float, None] = None
EXCHANGE_FEE: float = 0.00
HOST_POWER_USAGE: float = 70
MIN_PROFIT_PER_HOUR: float = 0

CONTROL_BOINC: bool = False
DEV_FEE: float = 0.05
SCRIPTED_RUN: bool = False
SKIP_TABLE_UPDATES: bool = False

ENABLE_TEMP_CONTROL = True  # Enable controlling BOINC based on temp. Default: False
START_TEMP: int = 65
STOP_TEMP: int = 75
TEMP_SLEEP_TIME: float = 10
TEMP_URL: str | None = None
TEMP_COMMAND: str | None = None
TEMP_REGEX: str = r"\d*"
TEMP_FUNCTION: Union[Callable[[], None], None] = lambda: None

DUMP_PROJECT_WEIGHTS: bool = False  # Dump weights assigned to projects
DUMP_PROJECT_PRIORITY: bool = (
    False  # Dump weights adjusted after considering current and past crunching time
)
DUMP_RAC_MAG_RATIOS: bool = False  # Dump the RAC:MAG ratios from each Gridcoin project
DUMP_DATABASE: bool = False  # Dump the DATABASE
# how many decimal places to round each stat to which is printed in the output table
ROUNDING_DICT: Dict[str, int] = {
    "MAGPERCREDIT": 5,
    "AVGMAGPERHOUR": 3,
    "USD/DAY R": 3,
    "USD/DAY P": 3,
    "ATIME": 1,
    "ACTIME": 1,
    "ACPT": 1,
    "TASKS": 0,
    "WTIME": 1,
    "CPUTIME": 1,
    "CREDIT/HR": 1,
    "R-WTIME": 1,
}

LOOKBACK_PERIOD = 30
ABORT_UNSTARTED_TASKS: bool = False
BOINC_DATA_DIR: Union[str, None] = None
GRIDCOIN_DATA_DIR: Union[str, None] = None
STRICT_GRIDCOIN: bool = False
RECALCULATE_STATS_INTERVAL: int = 60
PRICE_CHECK_INTERVAL: int = 720

STAT_FILE: str = "stats.json"
JOURNALD_NAME: str | None = None
LOG_LEVEL = "WARNING"
MAX_LOGFILE_SIZE_IN_MB = 10
ROLLING_WEIGHT_WINDOW = 60

BENCHMARKING_MINIMUM_WUS: float = 5
BENCHMARKING_MINIMUM_TIME: float = 10
BENCHMARKING_DELAY_IN_DAYS: float = 160
SKIP_BENCHMARKING: bool = False

BOINC_IP: str = "127.0.0.1"
BOINC_PORT: int = 31416
BOINC_USERNAME: Union[str, None] = None
BOINC_PASSWORD: Union[str, None] = None

CYCLE_SLEEP_TIME: float = (
    30  # There's no reason to loop through all projects more than once every 30 minutes
)
CYCLE_CHECK_TIME: float = 1  # Check for crunching once every 1 minute
CYCLE_SAVE_TIME: float = 10  # Save database every ten minutes
CYCLE_TEMP_TIME: float = 10  # Check for temperature once every ten minutes

EXIT_NNT: bool | None = None
EXTERNAL_REQUEST_PROXIES: Dict[str, str] = {}

# Constants
MIN_GB: float = 10
EXPECTED_GB_USED: float = 0.5
# Minimum time in minutes before re-asking a project for work who previously said
# they were out
MIN_RECHECK_TIME: int = 30
DEV_RPC_PORT = 31418
DEV_EXIT_TEST: bool = False  # Only used for testing
# Translates BOINC's CPU and GPU Mode replies into English. Note difference between
# keys integer vs string.
CPU_MODE_DICT = {1: "always", 2: "auto", 3: "never"}
GPU_MODE_DICT = {"1": "always", "2": "auto", "3": "never"}

# Some globals we need. I try to have all globals be ALL CAPS
TESTING: bool = False
FORCE_DEV_MODE = (
    False  # Used for debugging purposes to force crunching under dev account
)
CHECK_SIDESTAKE_RESULTS = False
DEV_FEE_MODE: str = "CRUNCH"  # valid values: CRUNCH|SIDESTAKE
CRUNCHING_FOR_DEV: bool = False
DEV_BOINC_PASSWORD = ""  # This is only used for printing to table, not used elsewhere
DEV_LOOP_RUNNING = False
BOINC_PROJECT_NAMES = {}
DATABASE: Dict[str, Any] = {}
DATABASE["TABLE_SLEEP_REASON"] = (
    ""  # Sleep reason printed in table, must be reset at script start
)
DATABASE["TABLE_STATUS"] = (
    ""  # Info status printed in table, must be reset at script start
)
LAST_KNOWN_CPU_MODE = None
LAST_KNOWN_GPU_MODE = None
ALL_PROJECT_URLS = set()
ALL_BOINC_PROJECTS = dict()
ATTACHED_PROJECT_SET = set()
ATTACHED_PROJECT_SET_DEV = set()
COMBINED_STATS = {}
COMBINED_STATS_DEV = {}
MAG_RATIO_SOURCE: Union[str, None] = None  # Valid values: WALLET|WEB
SAVE_STATS_DB = (
    {}
)  # Keeps cache of saved stats databases so we don't write more often than we need too


def verify_config_import(fname: str) -> bool:
    """
    Verify that config or user_config imported correctly
    @param fname: Filename to verify
    """
    if not os.path.isfile(fname + ".py"):
        return False
    try:
        module = importlib.import_module(fname)
    except Exception as e:
        print("Error opening user_config.py, using defaults! Error is: {}".format(e))
        return False
    for variable in dir(module):
        if variable.startswith("__"):
            continue
        # Verify all imports are upper-cased
        if str(variable) != variable.upper():
            error = "Error: variable from {} file {} is not uppercased. Make sure all variables you set are uppercased and named the same as the template in config.py".format(
                fname, variable
            )
            print(error)
            sys.exit(1)
    return True


# Import user settings from config
try:
    from config import *
except Exception as e:
    print("Error opening config.py, using defaults! Error is: {}".format(e))
# Import additional user settings from user_config
if verify_config_import("user_config"):
    _ROUNDING_DICT = copy.deepcopy(ROUNDING_DICT)
    from user_config import *

    ROUNDING_DICT = combine_dicts(_ROUNDING_DICT, ROUNDING_DICT)


loop = asyncio.get_event_loop()
HOST_COST_PER_HOUR = (HOST_POWER_USAGE / 1000) * LOCAL_KWH


# Setup logging
def setup_log():
    log = logging.getLogger()
    global LOG_LEVEL
    global JOURNALD_NAME
    global MAX_LOGFILE_SIZE_IN_MB
    if LOG_LEVEL == "NONE":
        log.setLevel(logging.CRITICAL + 10)
        log.addHandler(logging.NullHandler())
    else:
        log.setLevel(os.environ.get("LOGLEVEL", LOG_LEVEL))
        use_logfile = True
        if JOURNALD_NAME is not None:
            try:
                from systemd import journal

                log.addHandler(journal.JournalHandler(SYSLOG_IDENTIFIER=JOURNALD_NAME))
                use_logfile = False
            except Exception as e:
                print("Error importing systemd.journal, fallback to LOGFILE")
        if use_logfile:
            handler = logging.handlers.RotatingFileHandler(
                os.environ.get("LOGFILE", "debug.log"),
                maxBytes=MAX_LOGFILE_SIZE_IN_MB * 1024 * 1024,
                backupCount=1,
            )
            formatter = logging.Formatter(
                fmt="[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s"
            )
            handler.setFormatter(formatter)
            log.addHandler(handler)
        log.error("+++++++++++++++FTM STARTING+++++++++++++++++")
        log.error("+++++++++++++++FTM STARTING+++++++++++++++++")
        log.error("+++++++++++++++FTM STARTING+++++++++++++++++")
        log.error(
            "Start FTM log FTM version %s at %s",
            __version__,
            datetime.datetime.now().strftime("%m/%d/%Y, %H:%M:%S"),
        )
    return log


log = setup_log()
print_and_log = functools.partial(_print_and_log, log=log)

# Canonicalize URLs given to us by user
PREFERRED_PROJECTS = {resolve_url_database(k): v for k, v in PREFERRED_PROJECTS.items()}
IGNORED_PROJECTS = resolve_url_list_to_database(IGNORED_PROJECTS)

# If user has no preferred projects, their % of crunching should be 0
if len(PREFERRED_PROJECTS) == 0:
    PREFERRED_PROJECTS_PERCENT = 0

# Detect platform, guess BOINC and Gridcoin directories if needed
FOUND_PLATFORM = platform.system()
if BOINC_DATA_DIR is None:
    if FOUND_PLATFORM == "Linux":
        if os.path.isdir("/var/lib/boinc-client"):
            BOINC_DATA_DIR = "/var/lib/boinc-client"
        elif os.path.isdir("/var/lib/boinc"):
            BOINC_DATA_DIR = "/var/lib/boinc"
        else:
            BOINC_DATA_DIR = os.path.join(Path.home(), "BOINC/")
    elif FOUND_PLATFORM == "Darwin":
        BOINC_DATA_DIR = os.path.join("/Library/Application Support/BOINC Data/")
    else:
        BOINC_DATA_DIR = "C:\\ProgramData\\BOINC\\"
assert BOINC_DATA_DIR is not None, "BOINC_DATA_DIR is None!"
BOINC_DATA_DIR: str = BOINC_DATA_DIR

if GRIDCOIN_DATA_DIR is None:
    if FOUND_PLATFORM == "Linux":
        GRIDCOIN_DATA_DIR = os.path.join(Path.home(), ".GridcoinResearch/")
    elif FOUND_PLATFORM == "Darwin":
        GRIDCOIN_DATA_DIR = os.path.join(
            Path.home(), "Library/Application Support/GridcoinResearch/"
        )
    else:
        GRIDCOIN_DATA_DIR = os.path.join(
            Path.home(), "AppData\\Roaming\\GridcoinResearch\\"
        )
assert GRIDCOIN_DATA_DIR is not None, "GRIDCOIN_DATA_DIR is None!"
GRIDCOIN_DATA_DIR: str = GRIDCOIN_DATA_DIR

# === Fetch update ===


def update_fetch(
    update_text: Union[str, None] = None, current_ver: Union[str, None] = None
) -> Tuple[bool, bool, Union[str, None]]:
    """Check if FindTheMag updates are avialable.

    Check with FindTheMag repository on GitHub whether or not an update is
    available. If avaialble, inform the user and provide some information.

    Update checks are performed no often then once per week. Check times are
    stored in the database for future reference.

    Args:
        update_text: Used for testing purposes. Default: None
        current_ver: Added for testing purposes. Default: None

    Returns:
        A tuple consisting of:
            A bool, set to True if and update is available.
            A bool, set to True if the update is a security update.
            A string containing update related information.

    Raises:
        Exception: An error occured when attempting to parse the retrieved update file.
    """
    update_return = False
    return_string = ""
    security_update_return = False

    # Added for testing purposes
    if update_text is not None:
        resp = update_text
    else:
        resp = None
    if current_ver is None:
        current_ver = __version__
    from packaging.version import Version

    _current_ver = Version(current_ver)

    # If we've checked for updates in the last week, ignore
    delta = datetime.datetime.now() - DATABASE.get(
        "LASTUPDATECHECK", datetime.datetime(1997, 3, 3)
    )
    if abs(delta.days) < 7:
        return False, False, None
    # Get update status from Github
    if resp is None:
        import requests as req

        headers = req.utils.default_headers()
        headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36",
            }
        )
        url = "https://raw.githubusercontent.com/makeasnek/FindTheMag2/main/updates.txt"
        try:
            resp = req.get(url, headers=headers, proxies=EXTERNAL_REQUEST_PROXIES).text
        except Exception as e:
            DATABASE["TABLE_STATUS"] = "Error checking for updates {}".format(e)
            log.error("Error checking for updates {}".format(e))
            return False, False, None
        if "UPDATE FILE FOR FINDTHEMAG DO NOT DELETE THIS LINE" not in resp:
            DATABASE["TABLE_STATUS"] = "Error checking for updates invalid update file"
            log.error("Error checking for updates invalid update file")
            return False, False, None
    try:
        for line in resp.splitlines():
            if line.startswith("#"):
                continue
            if line == "":
                continue
            if "," not in line:
                continue
            split = line.split(",")
            version = Version(split[0])
            if split[1] == "1":
                security = True
            else:
                security = False
            notes = split[2]
            if version > _current_ver:
                if security:
                    security_update_return = True
                    update_return = True
                    return_string = (
                        return_string
                        + "Version {} available. This is an important security update. Changes include {}\n".format(
                            version, notes
                        )
                    )
                else:
                    update_return = True
                    return_string = (
                        return_string
                        + "Version {} available. Changes include {}\n".format(
                            version, notes
                        )
                    )
    except Exception as e:
        log.error("Error parsing update file")
    DATABASE["LASTUPDATECHECK"] = datetime.datetime.now()
    if return_string == "":
        return_string = None
    return update_return, security_update_return, return_string


def update_check() -> None:
    """Check if FindTheMag updates are avialable.

    Check for updates to the FindTheMag tool and logs information on any updates found.
    """
    available, security, print_me = update_fetch()
    if print_me is not None:
        print_and_log(
            print_me,
            ("DEBUG" if not available else "INFO") if not security else "WARNING",
        )


# === Fetch data ===


def get_grc_price() -> Union[float, None]:
    """
    Gets average GRC price from three online sources. Returns None if unable to determine
    """
    """Retrieve current average Gridcoin price.

    Calculates the average GRC price based on values from three online sources.

    Note: Retrieving the prices is dependent on the target website formatting. If the
    source website changes significantly, retrieval may fail until the relevant 
    search pattern in updated.

    Args:

    Returns:
        Average GCR price in decimal, or None if unable to determine price.

    Raises:
        Exception: An error occurred accessing an online GRC price source.
    """
    price, table_message, url_messages, info_log_messages, error_log_messages = (
        get_grc_price_from_sites(proxies=EXTERNAL_REQUEST_PROXIES)
    )

    for log_message in info_log_messages:
        log.info(log_message)

    for log_message in error_log_messages:
        log.error(log_message)

    if price:
        DATABASE["TABLE_STATUS"] = table_message

        for url_message in url_messages:
            print_and_log(url_message, "ERROR")

        return price

    DATABASE["TABLE_STATUS"] = table_message

    for url_message in url_messages:
        print_and_log(url_message, "ERROR")

    return DATABASE.get("GRCPRICE", 0)


def get_currency_rate(currency_code: str) -> Union[float, None]:
    """
    Gets average currency exchange rate from online sources. Returns None if unable to determine
    @sample_text: Used for testing. Just a "view source" of all pages added together
    """
    """Retrieve current average currency exchange rate.

    Calculates the average currency exchange rate based on values from three online sources.

    Note: Retrieving the prices is dependent on the target website formatting. If the
    source website changes significantly, retrieval may fail until the relevant 
    search pattern in updated.

    Args:

    Returns:
        Average currency exchange rate in decimal, or None if unable to determine price.

    Raises:
        Exception: An error occurred accessing an online currency exchange rate source.
    """
    price, table_message, url_messages, info_log_messages, error_log_messages = (
        get_currency_from_sites(currency_code, proxies=EXTERNAL_REQUEST_PROXIES)
    )

    for log_message in info_log_messages:
        log.info(log_message)

    for log_message in error_log_messages:
        log.error(log_message)

    if price:
        DATABASE["TABLE_STATUS"] = table_message

        for url_message in url_messages:
            print_and_log(url_message, "ERROR")

        return price

    DATABASE["TABLE_STATUS"] = table_message

    for url_message in url_messages:
        print_and_log(url_message, "ERROR")

    return DATABASE.get("CURRENCY_{}".format(currency_code), 1)


def get_approved_project_urls_web(
    query_result: Union[str, None] = None,
) -> Dict[str, str]:
    """List of projects currently witelised by Gridcoin.

    Gets current whitelist from the Gridcoinstats website. Limits fetching
    from website to once every 24 hours through caching list in database.

    Args:
        query_result: Used for testing.

    Returns:
        A dictionary mapping base URLs to project names.

    Raises:
        Exception: An error occurred fetching stats data from the website.
        Exception: An error occurred parsing data from the source website.
    """
    # Check if cache is available
    cache_available = "GSPROJECTLIST" in DATABASE and "GSRESOLVERDICT" in DATABASE
    # Return cached version if we have it and requested it < 24 hrs ago
    delta = datetime.datetime.now() - DATABASE.get(
        "LASTGRIDCOINSTATSPROJECTCHECK", datetime.datetime(1993, 3, 3)
    )
    if abs(delta.days) < 1 and cache_available:
        log.debug("Returning cached version of gridcoinstats data")
        return DATABASE["GSRESOLVERDICT"]

    # Otherwise, request it
    import json

    if query_result is None:
        import requests as req

        url = "https://www.gridcoinstats.eu/API/simpleQuery.php?q=listprojects"
        try:
            resp = req.get(url, proxies=EXTERNAL_REQUEST_PROXIES)
        except Exception as e:
            print("Error fetching magnitude stats from {}".format(url))
            log.error("Error fetching magnitude stats from {}: {}".format(url, e))
            if cache_available:
                return DATABASE["GSRESOLVERDICT"]
            else:
                log.debug("Exiting safely")
                safe_exit(None, None)
        else:
            if "BOINC" not in resp.text.upper():
                log.error("Error fetching magnitude stats from {}".format(url))
                if cache_available:
                    log.debug("Returning cached magnitude stats")
                    return DATABASE["GSRESOLVERDICT"]
                else:
                    log.debug("Exiting safely")
                    safe_exit(None, None)
            query_result = resp.text
    assert query_result is not None

    # Parse what we got back
    return_list: List[str] = []
    project_resolver_dict: Dict[str, str] = {}
    loaded_json = {}
    try:
        loaded_json = json.loads(query_result)
    except Exception as e:
        log.error("Error parsing data from Gridcoinstats {}".format(e))
        if cache_available:
            log.error("Returning old gridcoinstats data".format(e))
            return DATABASE["GSRESOLVERDICT"]
        else:
            print("Unable to continue...")
            safe_exit(None, None)
    for projectname, project in loaded_json.items():
        project_resolver_dict[projectname] = resolve_url_database(project["base_url"])
    DATABASE["LASTGRIDCOINSTATSPROJECTCHECK"] = datetime.datetime.now()
    DATABASE["GSPROJECTLIST"] = return_list
    DATABASE["GSRESOLVERDICT"] = project_resolver_dict
    return project_resolver_dict


# === Check!!! ===


def profitability_check(
    grc_price: float,
    exchange_fee: float,
    grc_sell_price: Union[None, float],
    project: str,
    min_profit_per_hour: float,
    combined_stats: dict,
) -> bool:
    """
    Returns True if crunching is profitable right now. False if otherwise or unable to determine.
    """
    if not grc_sell_price:
        grc_sell_price = 0.00
    if not isinstance(grc_price, float) and not isinstance(grc_price, int):
        return False
    combined_stats_extract = combined_stats.get(project)
    if not combined_stats_extract:
        log.error(
            "Error: Unable to calculate profitability for project {} bc we have no stats for it".format(
                project
            )
        )
        return False
    if "COMPILED_STATS" not in combined_stats_extract:
        log.error(
            "Error: Unable to calculate profitability for project {} bc we have no stats for it (COMPILED_STATS)".format(
                project
            )
        )
        return False
    if "AVGMAGPERHOUR" not in combined_stats_extract["COMPILED_STATS"]:
        log.error(
            "Error: Unable to calculate profitability for project {} bc we have no stats for it (AVGMAGPERHOUR)".format(
                project
            )
        )
        return False
    revenue_per_hour = (
        combined_stats_extract["COMPILED_STATS"]["AVGMAGPERHOUR"]
        / 4
        * max(grc_price, grc_sell_price)
    )
    exchange_expenses = revenue_per_hour * exchange_fee
    expenses_per_hour = exchange_expenses + HOST_COST_PER_HOUR
    profit = revenue_per_hour - expenses_per_hour
    if profit > min_profit_per_hour:
        log.debug(
            "Determined project {} is profitable. Rev is {} expenses is {} profit is {}".format(
                project, revenue_per_hour, expenses_per_hour, profit
            )
        )
        return True
    log.debug(
        "Determined project {} is NOT profitable. Rev is {} expenses is {} profit is {}".format(
            project, revenue_per_hour, expenses_per_hour, profit
        )
    )
    return False


def get_latest_wu_date(combined_stats_extract: List[str]) -> datetime.datetime:
    """
    Given list of WUs, return latest date or 1993 if unable to find one
    @param combined_stats_extract:
    @return:
    """
    latest_date = datetime.datetime(1993, 1, 1)
    for date in combined_stats_extract:
        datetimed = date_to_date(date)
        if datetimed > latest_date:
            latest_date = datetimed
    return latest_date


def benchmark_check(
    project_url: str,
    combined_stats: dict,
    benchmarking_minimum_wus: float,
    benchmarking_minimum_time: float,
    benchmarking_delay_in_days: float,
    skip_benchmarking: bool,
) -> bool:
    """
    Returns True if we should force crunch this project for benchmarking reasons. False otherwise
    """
    if skip_benchmarking:
        return False
    combined_stats_extract = combined_stats.get(project_url)
    if not combined_stats_extract:
        log.error("Unable to find project in benchmark_check".format(project_url))
        return True
    if (
        combined_stats_extract.get("COMPILED_STATS", {}).get("TOTALWALLTIME", 0)
        < benchmarking_minimum_time
    ):
        log.debug(
            "Forcing WU fetch on {} due to BENCHMARKING_MINIMUM_TIME".format(
                project_url
            )
        )
        return True
    if (
        combined_stats_extract["COMPILED_STATS"]["TOTALTASKS"]
        < benchmarking_minimum_wus
    ):
        log.debug(
            "Forcing WU fetch on {} due to benchmarking_minimum_tasks".format(
                project_url
            )
        )
        return True
    latest_date = get_latest_wu_date(combined_stats_extract["WU_HISTORY"])
    delta = datetime.datetime.now() - latest_date
    if abs(delta.days) > benchmarking_delay_in_days:
        log.debug(
            "Forcing WU fetch on {} due to BENCHMARKING_DELAY_IN_DAYS latest WU was {}".format(
                project_url, latest_date
            )
        )
        return True
    return False


# === Stats ===


def create_default_database() -> Dict[str, Any]:
    DATABASE: Dict[str, Any] = {}
    DATABASE["DEVTIMECOUNTER"] = 0
    DATABASE["FTMTOTAL"] = 0
    DATABASE["DEVTIMETOTAL"] = 0
    DATABASE["TABLE_STATUS"] = ""
    DATABASE["TABLE_SLEEP_REASON"] = ""
    return DATABASE


def generate_stats(
    combined_stats: dict,
    approved_project_urls: Union[List[str], None] = None,
    preferred_projects: Union[Dict[str, float], None] = None,
    ignored_projects: Union[List[str], None] = None,
    known_attached_projects: Union[Collection[str], None] = None,
    known_attached_projects_dev: Union[Collection[str], None] = None,
    known_boinc_projects: Union[Collection[str], None] = None,
    mag_ratios: Union[Dict[str, float], None] = None,
    quiet: bool = False,
    ignore_unattached: bool = False,
):
    if approved_project_urls is None:
        approved_project_urls = APPROVED_PROJECT_URLS
    if preferred_projects is None:
        preferred_projects = PREFERRED_PROJECTS
    if ignored_projects is None:
        ignored_projects = IGNORED_PROJECTS
    if known_attached_projects is None:
        known_attached_projects = ATTACHED_PROJECT_SET
    if known_attached_projects_dev is None:
        known_attached_projects_dev = ATTACHED_PROJECT_SET_DEV
    if known_boinc_projects is None:
        known_boinc_projects = ALL_PROJECT_URLS
    weak_stats = []
    if not quiet:
        print_and_log("Calculating project weights...", "INFO")
        print("Curing some cancer along the way...")
    # Calculate project weights w/ credit/hr
    final_project_weights = {}
    dev_project_weights = {}
    # Canonicalize PREFERRED_PROJECTS list
    to_del = []
    for url in preferred_projects.keys():
        weight = preferred_projects[url]
        canonicalized = resolve_url_database(url)
        if canonicalized != url:
            to_del.append(url)
        preferred_projects[canonicalized] = weight
    for url in to_del:
        del preferred_projects[url]
    # Ignore unattached projects if requested
    if ignore_unattached:
        for project in approved_project_urls:
            boincified_url = resolve_url_boinc_rpc(
                project,
                known_attached_projects=known_attached_projects,
                known_attached_projects_dev=known_attached_projects_dev,
                known_boinc_projects=known_boinc_projects,
            )
            if boincified_url not in ATTACHED_PROJECT_SET:
                ignored_projects.append(project)
                log.warning(
                    "Ignoring whitelisted project {} bc not attached".format(project)
                )
    combined_stats, unapproved_projects = add_mag_to_combined_stats(
        combined_stats,
        mag_ratios,
        approved_project_urls,
        list(preferred_projects.keys()),
    )

    # Detect attached projects which are not whitelisted or in PREFERRED_PROJECTS
    if len(unapproved_projects) > 0:
        if not quiet:
            print(
                "Warning: Projects below were found in your BOINC config but are not on the gridcoin approval list or your preferred projects list. If you want them to be given weight, be sure to add them to your preferred projects"
            )
            pprint.pprint(unapproved_projects)
        log.warning(
            "Warning: Projects below were found in your BOINC config but are not on the gridcoin approval list or your preferred projects list. If you want them to be given weight, be sure to add them to your preferred projects"
            + str(unapproved_projects)
        )
    most_efficient_projects = get_most_mag_efficient_projects(
        combined_stats, ignored_projects, quiet=quiet
    )
    if len(most_efficient_projects) == 0:
        print_and_log(
            "No projects have enough completed tasks to determine which is the most efficient. Assigning all projects 1",
            "WARNING",
        )
        total_preferred_weight = (
            1000 - (len(approved_project_urls)) + len(preferred_projects)
        )
        total_mining_weight = 0
    else:
        total_preferred_weight = (PREFERRED_PROJECTS_PERCENT / 100) * 1000
        total_mining_weight = 1000 - total_preferred_weight
    total_mining_weight_remaining = total_mining_weight
    # Assign weight of 1 to all projects which didn't make the cut
    for project_url in approved_project_urls:
        preferred_extract = preferred_projects.get(project_url)
        if preferred_extract:
            continue  # Exclude preferred projects
        if project_url in ignored_projects:
            final_project_weights[project_url] = 0
            dev_project_weights[project_url] = 0
            continue
        combined_stats_extract = combined_stats.get(project_url)
        if not combined_stats_extract:
            weak_stats.append(project_url)
            continue
        total_tasks = int(combined_stats_extract["COMPILED_STATS"]["TOTALTASKS"])
        if total_tasks < 10:
            weak_stats.append(project_url)
            continue
        if project_url not in most_efficient_projects or total_tasks < 10:
            weak_stats.append(project_url)
    # Assign weight of one to all project without enough stats
    for project_url in weak_stats:
        final_project_weights[project_url] = 1
        total_mining_weight_remaining -= 1
        dev_project_weights[project_url] = 0
    if len(weak_stats) > 0:
        if quiet:
            log.debug(
                "The following projects do not have enough stats to be calculated accurately, assigning them a weight of one: "
                + str(weak_stats)
            )
        else:
            print_and_log(
                "The following projects do not have enough stats to be calculated accurately, assigning them a weight of one: ",
                "INFO",
            )
            pprint.pprint(weak_stats)
    # Figure out weight to assign to most efficient projects, assign it
    if len(most_efficient_projects) == 0:
        per_efficient_project = 0
        per_efficient_project_dev = 0
    else:
        per_efficient_project = total_mining_weight_remaining / len(
            most_efficient_projects
        )
        per_efficient_project_dev = 1000 / len(most_efficient_projects)
    if total_mining_weight_remaining > 0:
        if not quiet:
            print_and_log(
                "Assigning "
                + str(total_mining_weight_remaining)
                + " weight to "
                + str(len(most_efficient_projects))
                + " mining projects which means "
                + str(per_efficient_project)
                + " per project ",
                "INFO",
            )
    for project_url in most_efficient_projects:
        if project_url not in final_project_weights:
            final_project_weights[project_url] = 0
            dev_project_weights[project_url] = 0
        final_project_weights[project_url] += per_efficient_project
        dev_project_weights[project_url] = per_efficient_project_dev
    # Assign weight to preferred projects
    for project_url, weight in preferred_projects.items():
        final_project_weights_extract = final_project_weights.get(project_url)
        preferred_project_weights_extract = preferred_projects.get(project_url, 0)
        if not final_project_weights_extract:
            final_project_weights[project_url] = 0
        intended_weight = (
            preferred_project_weights_extract / 100
        ) * total_preferred_weight
        final_project_weights[project_url] += intended_weight
    return (
        combined_stats,
        final_project_weights,
        total_preferred_weight,
        total_mining_weight,
        dev_project_weights,
    )


def actual_save_stats(db_dump: str, path: str) -> None:
    """
    Save a JSON database file. Normally saves to given path.txt unless the path is "stats"
    in which case it saves to STAT_FILE
    """
    if path:
        if path == "stats":
            path = STAT_FILE
    try:
        with open(path, "w") as fp:
            fp.write(db_dump)
    finally:
        pass


def save_stats(database: Any, path: Union[str, None] = None) -> None:
    """
    Caching function to save a database. If the database
    has changed, save it, otherwise don't.
    """
    if path is None:
        path = "stats"
    db_dump = json.dumps(database, default=json_default, sort_keys=True)
    db_hash = hash(db_dump)
    try:
        if path in SAVE_STATS_DB:
            if SAVE_STATS_DB[path] != db_hash:
                log.debug("Saving DB {}".format(path))
                actual_save_stats(db_dump, path)
            else:
                log.debug("Skipping save of DB {}".format(path))
        else:
            log.debug("Saving DB bc not in SAVE_STATS_DB {}".format(path))
            actual_save_stats(db_dump, path)
    except Exception as e:
        log.error("Error saving db {}{}".format(path, e))
    SAVE_STATS_DB[path] = db_hash


# === Lifecycle ===


def shutdown_dev_client(quiet: bool = False) -> None:
    """Shutdown developer BOINC client.

    Sends RPC quit command to running dev BOINC client.

    Args:
        quiet:

    Raises:
        Exception: An error occured shutting down the dev BOINC client.
    """
    # This is needed in case this function is called while main loop is still
    # waiting for an RPC command etc
    new_loop = asyncio.get_event_loop()
    log.info("Attempting to shut down dev client at safe_exit...")
    try:
        dev_rpc_client = new_loop.run_until_complete(
            setup_connection(BOINC_IP, DEV_BOINC_PASSWORD, port=DEV_RPC_PORT)
        )  # Setup dev BOINC RPC connection
        if dev_rpc_client is None:
            if not quiet:
                print_and_log("Dev client not running, no need to shutdown", "INFO")
            return
        authorize_response = new_loop.run_until_complete(
            dev_rpc_client.authorize(DEV_BOINC_PASSWORD)
        )  # Authorize dev RPC connection
        shutdown_response = new_loop.run_until_complete(
            run_rpc_command(dev_rpc_client, "quit")
        )
    except Exception as e:
        log.error("Error shutting down dev client {}".format(e))


async def dev_cleanup(
    rpc_client: Union[libs.pyboinc.rpc_client.RPCClient, None] = None,
) -> None:
    """
    Cleanup dev installation after use to save disk space, be nice to projects
    @param rpc_client:
    @return:
    """
    log.debug("in dev_cleanup")
    attached_projects = []
    if rpc_client is None:
        try:
            rpc_client = await setup_connection(
                BOINC_IP, DEV_BOINC_PASSWORD, port=DEV_RPC_PORT
            )  # Setup dev BOINC RPC connection
        except Exception as e:
            log.error(
                "Asked to connect to dev client in dev_cleanup but unable to: {}".format(
                    e
                )
            )
            return
    if rpc_client is None:
        log.error("In dev_cleanup not rpc_client x2")
        return
    try:
        await rpc_client.authorize(DEV_BOINC_PASSWORD)
    except Exception as e:
        log.error("Error authorizing dev client in dev_cleanup: {}".format(e))
    try:
        await kill_all_unstarted_tasks(rpc_client, True, True)
    except Exception as e:
        log.error("Error killing all unstarted tasks in dev_cleanup: {}".format(e))
    try:
        attached_projects, names_dict = await get_attached_projects(rpc_client)
    except Exception as e:
        log.error("Error getting project list in in dev_cleanup: {}".format(e))
    if isinstance(attached_projects, list):
        for project in attached_projects:
            log.debug("in dev_cleanup resetting project {}".format(project))
            try:
                await run_rpc_command(rpc_client, "project_reset", project)
            except Exception as e:
                log.error("Error resetting project in dev_cleanup: {}".format(project))
    shutdown_dev_client()


def safe_exit(_, __) -> None:
    """Safely exit Find The Mag.

    Safely exit tool by saving database, restoring original user preferences,
    and quitting dev BOINC client.

    Args: arg1 and arg2:
        Required by the signal handler library,
        but aren't used for anything inside this function
    """
    print_and_log(
        "Program exiting gracefully. Please be patient this may take a few minutes",
        "INFO",
    )

    # Backup most recent database save then save database to json file
    log.debug("Saving database")
    shutil.copy(STAT_FILE, "{}.backup".format(STAT_FILE))
    save_stats(DATABASE)
    # If BOINC control is not enabled, we can skip the rest of these steps
    if not CONTROL_BOINC:
        sys.exit()

    new_loop = (
        asyncio.get_event_loop()
    )  # This is needed in case this function is called while main loop is still waiting for an RPC command etc
    # Shutdown developer BOINC client, if running
    if (
        not should_crunch_for_dev(False) and CRUNCHING_FOR_DEV or DEV_EXIT_TEST
    ):  # If we are crunching for dev and won't start crunching again on next run
        new_loop.run_until_complete(dev_cleanup(rpc_client=None))
    shutdown_dev_client()

    # Restore original BOINC preferences
    if os.path.exists(override_dest_path):
        print_and_log("Restoring original preferences...", "DEBUG")
        try:
            shutil.copy(override_dest_path, override_path)
        except PermissionError as e:
            print_and_log(
                "Permission error restoring original BOINC preferences {}".format(e),
                "ERROR",
            )
            print("Be sure you have permission to edit this file")
            print(
                "Linux users try  'sudo usermod -aG boinc your_username_here' to fix this error".format(
                    override_path
                )
            )
            print(
                "Note that you will need to restart your machine for these changes to take effect"
            )
            print(
                "MacOS users: This is a known issue, if you find a good fix for it please let us know on Github!"
            )
        except Exception as e:
            print_and_log(
                "Error restoring original BOINC preferences {}".format(e), "ERROR"
            )
            print("Be sure you have permission to edit this file")
            print(
                "Linux users try  'sudo usermod -aG boinc your_username_here' to fix this error".format(
                    override_path
                )
            )
            print(
                "Note that you will need to restart your machine for these changes to take effect"
            )
    else:
        try:
            os.remove(override_dest_path)
        except Exception as e:
            print_and_log(
                "Error removing overritten BOINC preferences {}".format(e), "WARNING"
            )

    rpc_client = None
    try:
        rpc_client = new_loop.run_until_complete(
            setup_connection(BOINC_IP, BOINC_PASSWORD, port=BOINC_PORT)
        )  # Setup dev BOINC RPC connection
        if rpc_client is None:
            print_and_log(
                "Main BOINC client not running, cannot restore settings", "WARNING"
            )
            return
        authorize_response = new_loop.run_until_complete(
            rpc_client.authorize(BOINC_PASSWORD)
        )  # Authorize dev RPC connection
    except Exception as e:
        log.error("Error connecting to the main client {}".format(e))

    if rpc_client is not None:
        # Restore crunching settings pre-dev-mode
        try:
            if LAST_KNOWN_CPU_MODE is not None:
                new_loop.run_until_complete(
                    run_rpc_command(rpc_client, "set_gpu_mode", LAST_KNOWN_CPU_MODE)
                )
        except Exception as e:
            log.error(
                "Error restoring CPU crunching status in main client {}".format(e)
            )
        try:
            if LAST_KNOWN_GPU_MODE is not None:
                new_loop.run_until_complete(
                    run_rpc_command(rpc_client, "set_gpu_mode", LAST_KNOWN_GPU_MODE)
                )
        except Exception as e:
            log.error(
                "Error restoring GPU crunching status in main client {}".format(e)
            )

        if EXIT_NNT is not None:
            print_and_log(
                "Restoring: {}...".format("NNTing" if EXIT_NNT else "undo-NNTing"),
                "DEBUG",
            )
            try:
                if EXIT_NNT:
                    new_loop.run_until_complete(nnt_all_projects(rpc_client))
                else:
                    new_loop.run_until_complete(undo_nnt_all_projects(rpc_client))
            except Exception as e:
                log.error(
                    "Error {} in main client {}".format(
                        "NNTing" if EXIT_NNT else "undo-NNTing", e
                    )
                )

    try:
        loop.close()
    except Exception as e:
        log.error("Error closing an event loop: {}".format(e))
    sys.exit()


def temp_check() -> bool:
    """Checks if temperature is within acceptable limit.

    Confirms if we should keep crunching based on temperature, or not.

    Returns:
        True if we should keep crunching, False otherwise.

    Raises:
        Exception: An error occured attempting to read the temperature.
    """
    if not ENABLE_TEMP_CONTROL:
        return True
    text = ""
    if TEMP_URL:
        import requests as req

        try:
            text = req.get(TEMP_URL).text
        except Exception as e:
            print_and_log("Error checking temp: {}".format(e), "ERROR")
            return True
    elif TEMP_COMMAND:
        command = shlex.split(TEMP_COMMAND)
        try:
            text = subprocess.check_output(command).decode()
        except Exception as e:
            print_and_log("Error checking temp: {}".format(e), "ERROR")
            return True
    command_output = TEMP_FUNCTION() if TEMP_FUNCTION is not None else None
    match = None
    if command_output:
        text = str(command_output)
        match = re.search(TEMP_REGEX, text)
    if text:
        match = re.search(TEMP_REGEX, text)
    if match:
        try:
            found_temp = int(match.group(0))
            log.debug("Found temp {}".format(found_temp))
            return found_temp
        except Exception as e:
            print("Error parsing temp {} {}".format(match, e))
            return None
    else:
        print_and_log("No temps found!", "ERROR")
    return None


def temp_check(is_crunching: bool = True) -> bool:
    """Checks if temperature is within acceptable limit.

    Confirms if we should keep crunching based on temperature, or not.

    Returns:
        True if we should keep crunching, False otherwise.

    Raises:
        Exception: An error occured attempting to read the temperature.
    """
    if not ENABLE_TEMP_CONTROL:
        return True
    temp = temp_get()
    if temp is not None:
        if is_crunching and temp > STOP_TEMP:
            return False
        if not is_crunching and temp < START_TEMP:
            return True
        return is_crunching
    return True


async def get_existing_modes(
    rpc_client: libs.pyboinc.rpc_client.RPCClient,
) -> Tuple[Union[str, None], Union[str, None]]:
    global LAST_KNOWN_CPU_MODE
    global CPU_MODE_DICT
    global LAST_KNOWN_GPU_MODE
    global GPU_MODE_DICT
    # Get BOINC's starting CPU and GPU modes
    existing_mode_info = await run_rpc_command(rpc_client, "get_cc_status")
    existing_cpu_mode: Union[str, None] = None
    existing_gpu_mode: Union[str, None] = None
    if not existing_mode_info:
        print_and_log("Error getting cc status", "ERROR")
        if LAST_KNOWN_CPU_MODE:
            existing_cpu_mode = LAST_KNOWN_CPU_MODE
        if LAST_KNOWN_GPU_MODE:
            existing_gpu_mode = LAST_KNOWN_GPU_MODE
    else:
        existing_cpu_mode = existing_mode_info["task_mode"]
        if existing_cpu_mode in CPU_MODE_DICT:
            existing_cpu_mode = CPU_MODE_DICT[existing_cpu_mode]
            LAST_KNOWN_CPU_MODE = existing_cpu_mode
        else:
            print_and_log(
                "Error: Unknown cpu mode {}".format(existing_cpu_mode), "ERROR"
            )
        existing_gpu_mode = str(existing_mode_info["gpu_mode"])
        if existing_gpu_mode in GPU_MODE_DICT:
            existing_gpu_mode = GPU_MODE_DICT[existing_gpu_mode]
            LAST_KNOWN_GPU_MODE = existing_gpu_mode
        else:
            print_and_log(
                "Error: Unknown gpu mode {}".format(existing_gpu_mode), "ERROR"
            )
    return existing_cpu_mode, existing_gpu_mode


async def temp_sleep(
    boinc_rpc_client: libs.pyboinc.rpc_client.RPCClient, dev_loop: bool = False
) -> float:
    global ENABLE_TEMP_CONTROL
    global LAST_KNOWN_CPU_MODE
    global CPU_MODE_DICT
    global LAST_KNOWN_GPU_MODE
    global GPU_MODE_DICT
    global TEMP_SLEEP_TIME
    global DATABASE

    # If we have enabled temperature control, verify that crunching is
    # allowed at current temp
    if not ENABLE_TEMP_CONTROL:
        return 0
    # Get BOINC's starting CPU and GPU modes
    existing_cpu_mode, existing_gpu_mode = await get_existing_modes(boinc_rpc_client)
    if not existing_cpu_mode or not existing_gpu_mode:
        return 0
    # If temp is too high:
    if temp_check():
        return 0
    elapsed = 0
    while True:  # Keep sleeping until we pass a temp check
        log.debug("Sleeping due to temperature")
        # Put BOINC into sleep mode, automatically reverting if
        # script closes unexpectedly
        sleep_interval = str(int(((60 * TEMP_SLEEP_TIME) + 60)))
        _ = (
            await run_rpc_command(
                boinc_rpc_client, "set_run_mode", "never", sleep_interval
            ),
            await run_rpc_command(
                boinc_rpc_client, "set_gpu_mode", "never", sleep_interval
            ),
        )
        DATABASE["TABLE_SLEEP_REASON"] = "Temperature"
        update_table(dev_loop=dev_loop)
        await asyncio.sleep(60 * TEMP_SLEEP_TIME)
        elapsed += TEMP_SLEEP_TIME
        if temp_check(False):
            # Reset to initial crunching modes now that temp is satisfied
            _ = (
                await run_rpc_command(
                    boinc_rpc_client, "set_run_mode", existing_cpu_mode
                ),
                await run_rpc_command(
                    boinc_rpc_client, "set_gpu_mode", existing_gpu_mode
                ),
            )
            if (
                sleep_reason := DATABASE.pop("TABLE_SLEEP_REASON", None)
            ) != "Temperature":
                DATABASE["TABLE_SLEEP_REASON"] = sleep_reason
            update_table(dev_loop=dev_loop)
            return elapsed


async def custom_sleep(sleep_time: float, boinc_rpc_client, dev_loop: bool = False):
    """
    A function to sleep and update the DEVTIMECOUNTER
    sleep_time: duration in minutes to sleep
    dev_loop: True if we are in dev loop
    """
    log.debug("Sleeping for {}...".format(sleep_time))
    elapsed = 0
    next_save = 0
    next_temp = 0
    while elapsed < sleep_time:
        if elapsed >= next_temp:
            temp_sleep_time = await temp_sleep(boinc_rpc_client, dev_loop=dev_loop)
            elapsed += temp_sleep_time
            next_temp += temp_sleep_time + CYCLE_TEMP_TIME
        await asyncio.sleep(60 * CYCLE_CHECK_TIME)
        if await is_boinc_crunching(boinc_rpc_client):
            if dev_loop:
                DATABASE["DEVTIMETOTAL"] += CYCLE_CHECK_TIME
            else:
                DATABASE["FTMTOTAL"] += CYCLE_CHECK_TIME
        elapsed += CYCLE_CHECK_TIME
        # Save database every ten minutes
        if elapsed >= next_save:
            save_stats(DATABASE)
            next_save += CYCLE_SAVE_TIME
    # Save database at end of routine
    save_stats(DATABASE)


# === Dev Crunching ===


def setup_dev_boinc() -> str:
    """
    Do initial setup of and start dev boinc client. Returns RPC password. Returns 'ERROR' if unable to start BOINC
    """
    # Check if dev BOINC directory exists, create if it doesn't
    dev_path = os.path.abspath("DEVACCOUNT")
    boinc_executable = "/usr/bin/boinc"
    if "WINDOWS" in FOUND_PLATFORM.upper():
        boinc_executable = "C:\\Program Files\\BOINC\\boinc.exe"
    elif "DARWIN" in FOUND_PLATFORM.upper():
        boinc_executable = "/Applications/BOINCManager.app/Contents/resources/boinc"
    if not os.path.exists("DEVACCOUNT"):
        os.mkdir(dev_path)

    # Update settings to match user settings from main BOINC install
    global_settings_path = os.path.join(BOINC_DATA_DIR, "global_prefs.xml")
    override_path = os.path.join(BOINC_DATA_DIR, "global_prefs_override.xml")
    override_dest_path = os.path.join(
        os.path.join(os.getcwd(), "DEVACCOUNT"), "global_prefs_override.xml"
    )
    shutil.copy(global_settings_path, "DEVACCOUNT")
    if os.path.exists(override_path):
        shutil.copy(override_path, "DEVACCOUNT")
        # Read in the file
        with open(override_dest_path, "r") as file:
            filedata = file.read()
        # Replace the target string
        if "<disk_max_used_gb>" in filedata:
            filedata = re.sub(
                "<disk_max_used_gb>[^<]*</disk_max_used_gb>",
                "<disk_max_used_gb>5.000000</disk_max_used_gb>",
                filedata,
            )
        else:
            filedata = filedata.replace(
                "<global_preferences>",
                "<global_preferences><disk_max_used_gb>5.000000</disk_max_used_gb>",
            )

        # Write the file out again
        with open(override_dest_path, "w") as file:
            file.write(filedata)
    else:
        text_file = open(override_dest_path, "w")
        n = text_file.write(
            "<global_preferences><disk_max_used_gb>5.000000</disk_max_used_gb></global_preferences>"
        )
        text_file.close()
    boinc_arguments = [
        boinc_executable,
        "--allow_multiple_clients",
        "--dir",
        dev_path,
        "--gui_rpc_port",
        str(DEV_RPC_PORT),
    ]
    try:
        boinc_result = subprocess.Popen(
            boinc_arguments, stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL
        )
    except Exception as e:
        print("Error launching client for dev crunching {}".format(e))
        log.error("Error launching client for dev crunching {}".format(e))
        return "ERROR"
    sleep(6)
    auth_location = os.path.join(dev_path, "gui_rpc_auth.cfg")
    boinc_password = ""
    try:
        if os.path.exists(auth_location):
            with open(auth_location, "r") as file:
                data = file.read().rstrip()
                if data != "":
                    boinc_password = data
        else:
            boinc_password = ""
    except Exception as e:
        # This error can generally be disregarded on Linux/OSX
        if "WINDOWS" in FOUND_PLATFORM.upper():
            print("Error reading boinc RPC file at {}: {}".format(auth_location, e))
            log.error("Error reading boinc RPC file at {}: {}".format(auth_location, e))
        else:
            log.debug("Error reading boinc RPC file at {}: {}".format(auth_location, e))
    return boinc_password


def owed_to_dev() -> float:
    """

    @return: Hours currently owed to dev
    """
    total_time_in_hours = (max(DATABASE.get("FTMTOTAL", 0), 1) / 60) + max(
        DATABASE.get("DEVTIMETOTAL", 0), 1
    ) / 60
    dev_time_in_hours = max(DATABASE.get("DEVTIMETOTAL", 0), 1) / 60
    dev_owed_in_hours = max(0.01, DEV_FEE) * total_time_in_hours
    discrepancy = dev_owed_in_hours - dev_time_in_hours
    return discrepancy


def should_crunch_for_dev(dev_loop: bool) -> bool:
    if dev_loop:
        log.debug("Should not start dev crunching bc already in dev loop")
        return False
    if FORCE_DEV_MODE:
        log.debug("Should start dev crunching bc FORCE_DEV_MODE")
        return True
    if CHECK_SIDESTAKE_RESULTS:
        log.debug("Should skip dev mode bc CHECK_SIDESTAKE_RESULTS")
        return False
    discrepancy = owed_to_dev()
    if discrepancy > 100:
        log.debug(
            "Should start dev crunching due to discrepancy: {}".format(discrepancy)
        )
        return True
    log.debug("Should not start dev crunching, current owed is: {}".format(discrepancy))
    return False


def make_discrepancy_timeout(discrepancy: float) -> float:
    timeout = discrepancy
    if discrepancy < 0:
        if FORCE_DEV_MODE:
            timeout = 60
        else:
            timeout = 0
            log.error(
                "Discrepancy is < 0 this should not happen: {}".format(discrepancy)
            )
    return timeout


# === TUI ===


def sidestake_prompt(
    check_sidestake_results: bool, check_type: str, address: str
) -> None:
    """Enable sidestaking if approved by user.

    If sidestaking has not been enabled for the specified check_type, then prompt the user
    for enabling sidestaking, and enable in the Gridcoin wallet for the specified address
    and the entered percentage.

    Args:
        check_sidestake_results:
            True - sidestaking is currently enabled.
            False - sidestaking currently not enabled.
        check_type:
            'FOUNDATION' - sidestaking to the Gridcoin foundation.
            'DEVELOPER' - sidestaking to the FTM developer.
        address: Gridcoin address of the check_type.

    Raises:
        Exception: An error occurred while parsing the user's entered answer.
        Exception: An error occurred attempting to access the Gridcoin wallet
            configuration file.
    """
    # If user is sidestaking, skip rest of this function
    if check_sidestake_results:
        return
    message1 = ""
    message2 = ""
    if check_type == "FOUNDATION":
        message1 = (
            "It appears that you have not enabled sidestaking to the Gridcoin foundation in your wallet. We believe it is only fair that people benefiting from the Gridcoin network contribute back to it"
            "\nSidestaking enables you to contribute a small % of your staking profits (you can choose the %)"
            "\nWould you like to enable sidestaking?. "
            '\nPlease answer "Y" or "N" (without quotes)'
        )
        message2 = "What percent would you like to donate to the Gridcoin foundation? Donations go towards software development, promotion, and growth of the coin. Enter a number like 5 for 5%. Please enter whole numbers only"
    elif check_type == "DEVELOPER":
        message1 = (
            "Are you interested in sidestaking to the developers of this tool? "
            "\n This is optional (but required for MacOS users who the BOINC Control feature). I ask you to consider what gain in efficiency this tool can bring you and to donate a small portion of that gain (you can choose the %)."
            "\nPlease. I am trying to buy a pony."
            "\n If you use the BOINC control feature, you can choose whether to have FTM 'crunch for dev' or setup a sidestake. MacOS users can only choose the sidestake option"
            "\n You can always use FTM for free to read your BOINC client's stats and suggest project weights. "
            "\n Crunching for dev does not kick in until approximately 1000 hours of use and uses a minimum of 1% of processing power (default is 5, which can be changed in the config). All crunching still goes to BOINC, you just crunch under the dev's account"
            "\n Setting a sidestake amount also skips the 'crunching for dev' portion of this tool which will save you some disk space and CPU time. "
            '\n Do you want to setup a sidestake? Please answer "Y" or "N" (without quotes)'
        )
        message2 = "What percent would you like to donate to the developers of this tool? Enter a number like 5 for 5%. Please enter whole numbers only"
    answer = input(message1)
    while answer not in ["Y", "N", "y", "n"]:
        print("Error: Y or N not entered. Try again please :)")
        answer = input("")
    if answer == "N" or answer == "n":
        return
    answer = input(message2)
    converted_value = None
    while not converted_value:
        try:
            converted_value = int(answer)
        except Exception as e:
            print(
                "Hmm... that didn't seem to work, let's try again. Please enter a whole number"
            )
            answer = input("")
    conf_file = os.path.join(GRIDCOIN_DATA_DIR, "gridcoinresearch.conf")
    try:
        sidestake_entry = "sidestake=" + address + "," + str(converted_value)
        with open(conf_file, "a") as myfile:
            uppered = str(myfile).upper()
            if "enablesidestaking=1" not in uppered:
                myfile.write("enablesidestaking=1\n")
            if sidestake_entry.upper() not in uppered:
                myfile.write(sidestake_entry + "\n")
    except Exception as e:
        print_and_log(
            "Error saving sidestake settings, maybe no access to gridcoinresearch.conf? Trying to write to {} error was {}".format(
                conf_file, e
            ),
            "ERROR",
        )


def print_table(
    table_dict: Dict[str, Dict[str, str]],
    sortby: str = "GRC/DAY",
    sleep_reason: Union[str, None] = DATABASE["TABLE_SLEEP_REASON"],
    status: Union[str, None] = DATABASE["TABLE_STATUS"],
    dev_status: bool = False,
    clear: bool = False,
):
    """Outputs to console a text based table with current status and statistics.

    This is the main display of the program. It is refreshed automatically at set
    intervals. Statistics are displayed for each project as well as general information
    regarding the performance of FTM.

    Args:
        table_dict: Dictionary of project statistics.
        sortby: The table column attribute to sort the table rows by.
        sleep_reason: Reason to sleep.
        status: Most recent BOINC client status.
        dev_status: Whether or not crunching is being done for the FTM developer.
    """
    if len(table_dict) == 0:
        print(
            "No projects have any assigned credit yet, a pretty table will appear here once you have earned some credit."
        )
        # fmt: off
        print(r"""
                                                                              WNNXXXKKXW                     
                                                                        WNK0OkkxxkkkkdoK                     
                                                                    WX0kxdolx0XNNWWWNkoK                     
                                                                WN0kxxk0KX0xdON     NxdX                     
                                                              NKkxxOKNW    N0xdOXW  KokN                     
                                                           WXOxxOXW          N0xdOXNko0W                     
                                                        WKOkdkKN  NKOkkkOKN    N0xdxokN                      
                                                      WKxdxkXW  W0xdO0K0kdxKW    NOldK                       
                                                    WKxdOXWW    KdxX     XxdX    Nko0W                       
                                       W0kkOkkOkkkOkxdkXW       0okW     NkoK   Nko0W                        
                                      Xkdk0000000OdlxKW         NkdOXWWWXOdkN  Xxd0W                         
                                    WKddKW     WKxdON            N0xxxkxxk0N WKddKW                          
                                   NOdkX      N0dxXW         WW    WNXXXNW  NOdkX                            
                                 WXxd0W      XkldKW       WN0k0W          WKxd0W                             
                                W0dxKW     WKxdkxdOXW   N0kxx0N         WXkdkXW                              
                               NkdkN      WKdxXWWKxdOXN0xxk0N         WXkdkKW                                
                             WKxoOXXKK0OOkxooOW   N0doodONW         WXkdxKW                                  
                            W0oloxxxkkkO00K0kdkXW N0ddddOXWW      N0xoxKW                                    
                            WXKKXNNWWW      WKkdkOxd0NN0xdxOXW WXOxdooK                                      
                                              Xxllo0W   N0OxdOOxdkKXxoK                                      
                                            N0xdO0xdkXW WXKkoox0XW NkoK                                      
                                          N0xdON  WKxdkkxxxk0XW    NkoK                                      
                                        N0xdON      NklxKNWW       NxoK                                      
                                       WKkON        NkoK         WKkdxX                                      
                                        WW          XdxN      WXOxxkKN                                       
                                                   WOoOW   WXOxxkKNW                                         
                                                   NxdKWX0kxdk0NW                                            
                                                   Kddkkxxk0XW                                               
                                                  WOlox0XW                                                   
                                                  WX0XW                                                      


                 _____ _________________   ______________   __________     ________  ________
                / ___// ____/  _/ ____/ | / / ____/ ____/  /_  __/ __ \   /_  __/ / / / ____/
                \__ \/ /    / // __/ /  |/ / /   / __/      / / / / / /    / / / /_/ / __/   
               ___/ / /____/ // /___/ /|  / /___/ /___     / / / /_/ /    / / / __  / /___   
              /____/\____/___/_____/_/ |_/\____/_____/    /_/  \____/    /_/ /_/ /_/_____/   

                                          __  _______  ____  _   __
                                         /  |/  / __ \/ __ \/ | / /
                                        / /|_/ / / / / / / /  |/ / 
                                       / /  / / /_/ / /_/ / /|  /  
                                      /_/  /_/\____/\____/_/ |_/                                                                 



        """)
        # fmt: on
        return
    headings = []
    heading_length: Dict[str, int] = {}  # length of each heading column
    values = {}
    working_dict = copy.deepcopy(table_dict)
    # convert urls to nice names, add USD/GRC/hr
    for url in list(working_dict.keys()):
        name = project_url_to_name(url, ALL_BOINC_PROJECTS)
        if not name or name == url:
            name = project_url_to_name(url, BOINC_PROJECT_NAMES)
        if not name:
            name = url
        stats = table_dict[url]
        working_dict[name] = stats
        if name != url:
            del working_dict[url]
        # add usd/grc/hr to each project
        if mag_per_hour := working_dict[name].get("MAG/HR"):
            grc_per_hour = float(mag_per_hour) / 4
            grc_per_day = (grc_per_hour) * 24
            rounded_grc_per_hour = str(
                round(grc_per_hour, ROUNDING_DICT.get("GRC/HR", 3))
            )
            rounded_grc_per_day = str(
                round(grc_per_day, ROUNDING_DICT.get("GRC/HR", 3))
            )
            working_dict[name]["GRC/HR"] = rounded_grc_per_hour
            working_dict[name]["GRC/DAY"] = rounded_grc_per_day
            if float(mag_per_hour) != 0:
                revenue_per_day = (
                    (grc_per_day)
                    * DATABASE.get("GRCPRICE", 0)
                    * DATABASE.get("CURRENCY_{}".format(CURRENCY_CODE), 1)
                )
                exchange_expenses = revenue_per_day * EXCHANGE_FEE
                expenses_per_day = exchange_expenses + (HOST_COST_PER_HOUR * 24)
                profit = revenue_per_day - expenses_per_day
                rounded_revenue_per_day = str(
                    round(revenue_per_day, ROUNDING_DICT.get("USD/DAY R", 3))
                )
                rounded_profit_per_day = str(
                    round(profit, ROUNDING_DICT.get("USD/DAY P", 3))
                )
                working_dict[name]["{}/DAY R/P".format(CURRENCY_CODE)] = "{}/{}".format(
                    rounded_revenue_per_day, rounded_profit_per_day
                )
            else:
                working_dict[name]["{}/DAY R/P".format(CURRENCY_CODE)] = "0"
            del working_dict[name]["MAG/HR"]

    # figure out table headings
    for url, stats in working_dict.items():
        for key, value in stats.items():
            if key not in headings:
                headings.append(key)
            heading_length[key] = len(key)
            if key not in values:
                values[key] = []
            if value not in values[key]:
                values[key].append(value)

    longest_url = len(max(working_dict.keys(), key=len))
    table_width = longest_url + len(str(values.keys()))
    # print header
    ## print first line
    print("*" * table_width)
    print(
        "*" + center_align("FINDTHEMAG V{}".format(__version__), table_width - 2) + "*"
    )
    print("*" * table_width)

    ## print rest of header
    padding_str = " " * (longest_url + 1)
    print("*" + padding_str, end="|")
    for heading in headings:
        print(center_align(heading, heading_length[heading]) + "|", end="")
    print("")

    # print contents
    sortedprojects = sorted(
        working_dict.keys(),
        key=lambda a: float(working_dict[a].get(sortby, 0)),
        reverse=True,
    )
    for url in sortedprojects:
        stats = working_dict[url]
        url_padding = longest_url - len(url)
        url_padding_str = " " * url_padding
        print("* " + url.lower() + url_padding_str, end="|")
        for heading in headings:
            value = stats.get(heading, "")
            print(left_align(value, heading_length[heading]), end="|")
        print("")

    # print bottom bar
    print("*" * table_width)
    if not sleep_reason:
        sleep_reason = "NONE"
    elif sleep_reason == "":
        sleep_reason = "NONE"
    bottom_bar_1 = (
        "*"
        + left_align("Sleep reason: {}".format(sleep_reason), total_len=60, min_pad=1)
        + "*"
    )
    bottom_bar_2 = left_align("Info: {}".format(status), total_len=60, min_pad=1)
    bottom_bar_3 = (
        left_align(
            "GRC Price: {:.6f}".format(
                DATABASE.get("GRCPRICE", 0.00000)
                * DATABASE.get("CURRENCY_{}".format(CURRENCY_CODE), 1)
            ),
            total_len=19,
            min_pad=1,
        )
        + "*"
    )
    print(bottom_bar_1 + bottom_bar_2 + bottom_bar_3)
    if dev_status or DEV_LOOP_RUNNING:
        print(
            "Crunching for developer, main BOINC is paused. You can monitor by connecting BOINC manager to 127.0.0.1:31418 pwd: {}".format(
                DEV_BOINC_PASSWORD
            )
        )
    # print improved stats
    addl = ""
    curr_avg_mag = get_avg_mag_hr(COMBINED_STATS)
    if curr_avg_mag > DATABASE["STARTMAGHR"] and DATABASE["STARTMAGHR"] > 0:
        increase = (curr_avg_mag - DATABASE["STARTMAGHR"]) / DATABASE["STARTMAGHR"]
        addl = " That's an increase of {:.2f}%!".format(increase * 100)
    print(
        "When you started using this tool, your average mag/hr was: {:.4f} now it is {:.4f}".format(
            DATABASE["STARTMAGHR"], get_avg_mag_hr(COMBINED_STATS)
        )
        + addl
    )
    print(
        "Hours crunched for you vs dev: {:.1f}|{:.1f} ".format(
            DATABASE["FTMTOTAL"] / 60, DATABASE["DEVTIMETOTAL"] / 60
        )
        + " Dev fee mode: {}".format(DEV_FEE_MODE.lower())
    )
    # print final line
    if not CHECK_SIDESTAKE_RESULTS:
        print(
            "Consider donating to this app's development directly or via sidestake: RzUgcntbFm8PeSJpauk6a44qbtu92dpw3K. Sidestaking means you can skip crunching for dev"
        )
    print("Use Ctrl+C to exit FTM and return BOINC to previous config")
    print(
        'HOURSOFF= How far off we are between "intended" (based on weight) and "actual crunch time"'
    )
    print(
        "ATIME and ACTIME are average wall time and CPU time per task, totals displayed as WTIME/CPUTIME"
    )
    print(
        "RWTIME is wall-time crunched during window (default is 60 days). Windows help FTM track changes in how projects award credit"
    )
    print(
        "{}/DAY R/P is revenue and profit per day in {}. Uses electrical costs from your user_config.py".format(
            CURRENCY_CODE, CURRENCY_CODE
        )
    )
    print("*" * table_width)


def update_table(
    sleep_reason: Union[str, None] = None,
    status: Union[str, None] = None,
    dev_status: bool = False,
    dev_loop: bool = False,
    clear: bool = True,
):
    """
    Function to update table printed to user.
    :param status = Most recent status "waiting for xfers, starting crunching on x, etc"
    """
    # Don't update table in dev loop because all our variables reference
    # dev install, not main one
    if dev_loop or SKIP_TABLE_UPDATES:
        return
    if not sleep_reason:
        sleep_reason = DATABASE.get("TABLE_SLEEP_REASON", "")
    if not status:
        status = DATABASE.get("TABLE_STATUS", "")
    rename_dict = {
        "TOTALTASKS": "TASKS",
        "TOTALTIME(HRS)": "TIME",
        "TOTALCPUTIME(HRS)": "CPUTIME",
        "AVGCREDITPERHOUR": "CREDIT/HR",
        "AVGMAGPERHOUR": "MAG/HR",
        "XDAYWALLTIME": "RWTIME",
        "AVGWALLTIME": "ATIME",
        "AVGCREDITPERTASK": "ACPT",
        "TOTALWALLTIME": "WTIME",
        "TOTALCPUTIME": "CPUTIME",
        "AVGCPUTIME": "ACTIME",
    }
    ignore_list = ["MAGPERCREDIT"]
    # generate table to print pretty
    if clear:
        os.system("cls" if os.name == "nt" else "clear")  # clear terminal
    table_dict = {}
    for project_url, stats_dict in COMBINED_STATS.items():
        table_dict[project_url] = {}
        priority_results_extract = priority_results.get(project_url)
        if priority_results_extract:
            table_dict[project_url]["HOURSOFF"] = str(
                round(float(priority_results_extract), 2)
            )
        else:
            table_dict[project_url]["HOURSOFF"] = str(round(float(0), 2))
        for stat_name, stat_value in stats_dict["COMPILED_STATS"].items():
            if stat_name in ignore_list:
                continue
            renamed = stat_name
            if stat_name in rename_dict:
                renamed = rename_dict[stat_name]
            rounding = ROUNDING_DICT.get(stat_name, 3)
            table_dict[project_url][renamed] = str(round(float(stat_value), rounding))
        final_project_weights_extract = FINAL_PROJECT_WEIGHTS.get(project_url)
        if final_project_weights_extract:
            table_dict[project_url]["WEIGHT"] = str(final_project_weights_extract)
        else:
            table_dict[project_url]["WEIGHT"] = "0"
    print_table(
        table_dict,
        sortby="GRC/DAY",
        sleep_reason=sleep_reason,
        status=status,
        dev_status=dev_status,
        clear=clear,
    )


# === Main Loop ===


async def boinc_loop(
    dev_loop: bool = False,
    rpc_client: Union[libs.pyboinc.rpc_client.RPCClient, None] = None,
    client_rpc_client: Union[libs.pyboinc.rpc_client.RPCClient, None] = None,
    time: int = 0,
):
    """
    Main routine which manages BOINC
    :param dev_loop: set to True if we are crunching for developer
    :param rpc_client BOINC rpc client. Pass in developer client if crunching for developer
    :param client_rpc_client client BOINC rpc client, as it must be accessed in dev mode and kept in suspend
    :param time How long to crunch for. Only used by dev mode at the moment
    """
    # If we are not passed this variable, it means we are not crunching for dev,
    # so we fallback to global BOINC rpc
    if not client_rpc_client:
        client_rpc_client = rpc_client
    assert rpc_client is not None, "rpc_client must be provided"
    assert client_rpc_client is not None, "client_rpc_client must be provided"
    existing_cpu_mode = None
    existing_gpu_mode = None
    # These variables are referenced outside the loop
    # (or in recursive calls of the loop) so should be made global
    global COMBINED_STATS
    global COMBINED_STATS_DEV
    global FINAL_PROJECT_WEIGHTS
    global FINAL_PROJECT_WEIGHTS_DEV
    global total_preferred_weight
    global highest_priority_projects
    global priority_results
    global DEV_PROJECT_WEIGHTS
    global DEV_BOINC_PASSWORD
    global DEV_LOOP_RUNNING
    global LAST_KNOWN_CPU_MODE
    global LAST_KNOWN_GPU_MODE
    global ATTACHED_PROJECT_SET
    global ATTACHED_PROJECT_SET_DEV
    global BOINC_PROJECT_NAMES
    global MAG_RATIOS
    global CRUNCHING_FOR_DEV
    if dev_loop:
        mode = "DEV"
        CRUNCHING_FOR_DEV = True
    else:
        mode = "CLIENT"
        CRUNCHING_FOR_DEV = False
    if mode not in DATABASE:
        DATABASE[mode] = {}
    if DUMP_DATABASE:
        save_stats(DATABASE, "DATABASE_DUMP")

    # Note yoyo@home does not support weak auth so it can't be added here
    # URLs must be in canonicalized database format
    DEV_PROJECT_DICT = {
        "SECH.ME/BOINC/AMICABLE": "48989_50328a1561506cd0dcd10476106fda82",
        "ASTEROIDSATHOME.NET/BOINC": "476179_e114636a09b4d451daacc9488c1f3b83",
        "EINSTEINATHOME.ORG": "1043421_4a19901b420ccc1aab1df9021e59e5ee",
        "EINSTEIN.PHYS.UWM.EDU": "1043421_4a19901b420ccc1aab1df9021e59e5ee",
        "GPUGRID.NET": "575631_e05399c996a36746d603d0edcc6fdcb2",
        "MILKYWAY.CS.RPI.EDU/MILKYWAY": "3206506_1ff09dd6be13aabc509b535934de40f8",
        "ESCATTER11.FULLERTON.EDU/NFS": "2583967_720a4730bb15ae246935cf911d496ba3",
        "NUMBERFIELDS.ASU.EDU/NUMBERFIELDS": "860933_e543b27624d04eea09d74f2cf39afd31",
        "BOINC.MULTI-POOL.INFO/LATINSQUARES": "33541_de185e7045673c1485d16148683c22d9",
        "BOINC.BAKERLAB.ORG/ROSETTA": "2382329_f817670777925b63d7090fa50ac11e0b",
        "SRBASE.MY-FIREWALL.ORG/SR5": "2909_3675395fe23cc846696609fc72114b17",
        "SIDOCK.SI/SIDOCK": "9302_bfbe2dcf1bc6e6f50fbc4c67841e8624",
        "GENE.DISI.UNITN.IT/TEST": "3813_54b95766c943370c5517bce39742b4fe",
        "UNIVERSEATHOME.PL/UNIVERSE": "239667_e7bfb47b3f94750632796b03b2bc7954",
        "WORLDCOMMUNITYGRID.ORG": "1156028_7f2601c3a6dc1b1b9f7eb99261db96f0",
    }

    while True:
        discrepancy = owed_to_dev()
        # If we have done sufficient crunching in dev mode, exit dev loop.
        # Closing dev client is done after exiting loop.
        if discrepancy < 1 and not FORCE_DEV_MODE and dev_loop:
            return None

        # Re-authorize in case we have become de-authorized since last run.
        # This is put in a try b/c sometimes it throws exceptions
        while True:
            try:
                authorize_response = await rpc_client.authorize()
                temp_project_list, BOINC_PROJECT_NAMES = await get_attached_projects(
                    rpc_client
                )
                if mode == "DEV":
                    ATTACHED_PROJECT_SET_DEV.update(temp_project_list)
                else:
                    ATTACHED_PROJECT_SET.update(temp_project_list)
                # Update ALL_BOINC_PROJECTS if we find any new names
                for url, project_name in BOINC_PROJECT_NAMES.items():
                    if url not in ALL_BOINC_PROJECTS:
                        ALL_BOINC_PROJECTS[url] = project_name
                        ALL_BOINC_PROJECTS[resolve_url_database(url)] = project_name
            except Exception as e:
                print_and_log(
                    "Transient error connecting to BOINC, sleeping 30s: {}", "ERROR"
                )
                await asyncio.sleep(30)
            else:
                break

        # If we haven't re-calculated stats or fetched mag recently enough, do it
        stats_calc_delta = datetime.datetime.now() - DATABASE.get(
            "STATSLASTCALCULATED", datetime.datetime(1997, 3, 3)
        )
        mag_fetch_delta = datetime.datetime.now() - DATABASE.get(
            "MAGLASTCHECKED", datetime.datetime(1997, 3, 3)
        )
        if (
            (abs(mag_fetch_delta.days) * 24 * 60) + (abs(mag_fetch_delta.seconds) / 60)
        ) > 1442:  # Only re-check mag once a day:
            if MAG_RATIO_SOURCE == "WALLET":
                assert grc_client is not None, "GRC client must be provided"
                MAG_RATIOS = ProjectMagRatio.get_project_mag_ratios(
                    grc_client,
                    LOOKBACK_PERIOD,
                    dump_rac_mag_ratios=(
                        (lambda d: save_stats(d, "RAC_MAG_RATIOS"))
                        if DUMP_RAC_MAG_RATIOS
                        else None
                    ),
                )
                log.debug(
                    "Fetched MAG RATIOS from wallet, answer is: {}".format(MAG_RATIOS)
                )
            elif MAG_RATIO_SOURCE == "WEB":
                MAG_RATIOS = ProjectMagRatio.get_project_mag_ratios_from_url(
                    project_resolver_dict=get_approved_project_urls_web(),
                    lookback_period=LOOKBACK_PERIOD,
                    dump_rac_mag_ratios=(
                        (lambda d: save_stats(d, "RAC_MAG_RATIOS"))
                        if DUMP_RAC_MAG_RATIOS
                        else None
                    ),
                    proxies=EXTERNAL_REQUEST_PROXIES,
                )
                log.debug(
                    "Fetched MAG RATIOS from web, answer is: {}".format(MAG_RATIOS)
                )
        if (
            (abs(stats_calc_delta.days) * 24 * 60)
            + (abs(stats_calc_delta.seconds) / 60)
        ) > RECALCULATE_STATS_INTERVAL:  # Only re-calculate stats every x minutes
            log.debug("Calculating stats..")
            DATABASE["STATSLASTCALCULATED"] = datetime.datetime.now()
            COMBINED_STATS = config_files_to_stats(
                BOINC_DATA_DIR, rolling_weight_window=ROLLING_WEIGHT_WINDOW
            )
            # Not sure what this line did but commented out, we'll see if anything breaks
            # total_time = combined_stats_to_total_time(COMBINED_STATS)
            if dev_loop:
                (
                    COMBINED_STATS_DEV,
                    FINAL_PROJECT_WEIGHTS,
                    total_preferred_weight,
                    total_mining_weight,
                    DEV_PROJECT_WEIGHTS,
                ) = generate_stats(
                    combined_stats=COMBINED_STATS,
                    approved_project_urls=APPROVED_PROJECT_URLS,
                    preferred_projects=PREFERRED_PROJECTS,
                    ignored_projects=IGNORED_PROJECTS,
                    quiet=True,
                    ignore_unattached=True,
                    mag_ratios=MAG_RATIOS,
                )
            else:
                (
                    COMBINED_STATS,
                    FINAL_PROJECT_WEIGHTS,
                    total_preferred_weight,
                    total_mining_weight,
                    DEV_PROJECT_WEIGHTS,
                ) = generate_stats(
                    combined_stats=COMBINED_STATS,
                    approved_project_urls=APPROVED_PROJECT_URLS,
                    preferred_projects=PREFERRED_PROJECTS,
                    ignored_projects=IGNORED_PROJECTS,
                    quiet=True,
                    ignore_unattached=True,
                    mag_ratios=MAG_RATIOS,
                )
            if DUMP_PROJECT_WEIGHTS:
                if not dev_loop:
                    save_stats(FINAL_PROJECT_WEIGHTS, "FINAL_PROJECT_WEIGHTS")
                else:
                    save_stats(FINAL_PROJECT_WEIGHTS, "FINAL_PROJECT_WEIGHTS_DEV")
            # Get list of projects ordered by priority
            highest_priority_projects, priority_results = get_highest_priority_project(
                combined_stats=COMBINED_STATS,
                project_weights=FINAL_PROJECT_WEIGHTS,
                attached_projects=ATTACHED_PROJECT_SET,
                quiet=True,
            )
            if DUMP_PROJECT_PRIORITY:
                if dev_loop:
                    save_stats(priority_results, "PRIORITY_RESULTS_DEV")
                else:
                    save_stats(priority_results, "PRIORITY_RESULTS")
            log.debug(
                "Highest priority projects are: " + str(highest_priority_projects)
            )
            # Print some pretty stats
            update_table(dev_loop=dev_loop)

        log.info(
            "Highest priority project is {} in mode".format(
                highest_priority_projects[0], mode
            )
        )
        await nnt_all_projects(rpc_client)  # NNT all projects

        # If we haven't checked GRC prices in a while, do it
        price_check_delta = datetime.datetime.now() - DATABASE.get(
            "GRCPRICELASTCHECKED", datetime.datetime(1993, 3, 3)
        )
        price_check_calc = (abs(price_check_delta.days) * 24 * 60) + (
            abs(price_check_delta.seconds) / 60
        )
        if price_check_calc > max(PRICE_CHECK_INTERVAL, 60):
            grc_price = get_grc_price()
            DATABASE["GRCPRICELASTCHECKED"] = datetime.datetime.now()
            if grc_price is not None:
                DATABASE["GRCPRICE"] = grc_price
        grc_price = DATABASE.get("GRCPRICE", 0)

        # If we haven't checked currency exchange rate in a while, do it
        price_check_delta = datetime.datetime.now() - DATABASE.get(
            "CURRENCYLASTCHECKED_{}".format(CURRENCY_CODE),
            datetime.datetime(1993, 3, 3),
        )
        price_check_calc = (abs(price_check_delta.days) * 24 * 60) + (
            abs(price_check_delta.seconds) / 60
        )
        if price_check_calc > max(PRICE_CHECK_INTERVAL, 60):
            currency_rate = get_currency_rate(CURRENCY_CODE)
            DATABASE["CURRENCYLASTCHECKED_{}".format(CURRENCY_CODE)] = (
                datetime.datetime.now()
            )
            if currency_rate is not None:
                DATABASE["CURRENCY_{}".format(CURRENCY_CODE)] = currency_rate
        currency_rate = DATABASE.get("CURRENCY_{}".format(CURRENCY_CODE), 1)
        # Check profitability of all projects, if none profitable
        # (and user doesn't want unprofitable crunching), sleep for 1hr
        if ONLY_BOINC_IF_PROFITABLE and not dev_loop:
            profitability_list = []
            for project in highest_priority_projects:
                profitability_result = profitability_check(
                    grc_price=grc_price * currency_rate,
                    exchange_fee=EXCHANGE_FEE,
                    grc_sell_price=GRC_SELL_PRICE,
                    project=project,
                    min_profit_per_hour=MIN_PROFIT_PER_HOUR,
                    combined_stats=COMBINED_STATS,
                )
                benchmarking_result = benchmark_check(
                    project_url=project,
                    combined_stats=COMBINED_STATS,
                    benchmarking_minimum_wus=BENCHMARKING_MINIMUM_WUS,
                    benchmarking_minimum_time=BENCHMARKING_MINIMUM_TIME,
                    benchmarking_delay_in_days=BENCHMARKING_DELAY_IN_DAYS,
                    skip_benchmarking=SKIP_BENCHMARKING,
                )
                profitability_list.append(profitability_result)
                profitability_list.append(benchmarking_result)
            if True not in profitability_list:
                log.info(
                    "No projects currently profitable and no benchmarking required, sleeping for 1 hour and killing all non-started tasks"
                )
                try:
                    tasks_list = await get_task_list(rpc_client)
                    await kill_all_unstarted_tasks(rpc_client=rpc_client)
                except Exception as e:
                    pass
                await nnt_all_projects(rpc_client)
                DATABASE["TABLE_SLEEP_REASON"] = (
                    "No profitable projects and no benchmarking required, sleeping 1 hr, killing all non-started tasks"
                )
                update_table(dev_loop=dev_loop)
                await asyncio.sleep(60 * 60)
                continue

        await temp_sleep(rpc_client, dev_loop=dev_loop)

        # If we are due to run under dev account, do it
        if should_crunch_for_dev(dev_loop):
            CRUNCHING_FOR_DEV = True
            dev_boinc_password = setup_dev_boinc()  # Setup and start dev boinc
            DEV_BOINC_PASSWORD = dev_boinc_password
            dev_rpc_client = None
            if dev_boinc_password == "ERROR":
                log.error("Error setting up crunching to developer account")
            else:
                # Setup dev RPC connection, it may take a few tries while we
                # wait for it to come online
                tries = 1
                tries_max = 5
                dev_rpc_client = None
                while tries <= tries_max:
                    try:
                        dev_rpc_client = await setup_connection(
                            BOINC_IP, DEV_BOINC_PASSWORD, port=DEV_RPC_PORT
                        )  # Setup dev BOINC RPC connection
                        if not dev_rpc_client:
                            raise Exception("Error connecting to boinc dev client")
                        authorize_response = await dev_rpc_client.authorize(
                            DEV_BOINC_PASSWORD
                        )  # Authorize dev RPC connection
                    except Exception as e:
                        log.error("Error connecting to BOINC dev client {}".format(e))
                    else:
                        if tries > 1:
                            log.info("Finally connected to BOINC dev client {}")
                        break
                    await asyncio.sleep(30)
                    tries += 1
                    if tries > tries_max:
                        log.error("Giving up on connecting to BOINC dev client")
            if dev_rpc_client:
                # Set main BOINC to suspend until we're done crunching in dev mode.
                # It will automatically re-enable itself in 100x the time if nothing
                # is done.
                # This allows for non-graceful exits of this script to not brick
                # client's BOINC and considerations that dev account may not be
                # crunching full time if client is actively using computer.
                existing_cpu_mode, existing_gpu_mode = await get_existing_modes(
                    rpc_client
                )
                if (
                    existing_cpu_mode and existing_gpu_mode
                ):  # We can't do this if we don't know what mode to revert back to
                    discrepancy = owed_to_dev()
                    timeout = make_discrepancy_timeout(discrepancy)
                    _ = (
                        await run_rpc_command(
                            dev_rpc_client,
                            "set_run_mode",
                            "always",
                            str(timeout * 60 * 60 * 10),
                        ),
                        await run_rpc_command(
                            dev_rpc_client,
                            "set_gpu_mode",
                            "always",
                            str(timeout * 60 * 60 * 10),
                        ),
                    )
                    log.info("Starting crunching under dev account, entering dev loop")
                    DATABASE["TABLE_SLEEP_REASON"] = (
                        "Crunching for developer's account, {}% of crunching total".format(
                            DEV_FEE * 100
                        )
                    )
                    DEV_LOOP_RUNNING = True
                    update_table(dev_loop=dev_loop)
                    await boinc_loop(
                        dev_loop=True,
                        rpc_client=dev_rpc_client,
                        client_rpc_client=rpc_client,
                        time=DATABASE["DEVTIMECOUNTER"],
                    )  # Run the BOINC loop :)
                    await dev_cleanup(dev_rpc_client)
                    log.debug("dev_cleanup_called it appears boinc_loop ended")
                    update_table(dev_loop=dev_loop)
                    DEV_LOOP_RUNNING = False
                    # Re-enable client BOINC
                    _ = (
                        await run_rpc_command(
                            rpc_client, "set_run_mode", existing_cpu_mode
                        ),
                        await run_rpc_command(
                            rpc_client, "set_gpu_mode", existing_gpu_mode
                        ),
                    )
                else:
                    log.error("Unable to start dev mode due to unknown last mode")

        # Loop through each project in order of priority and request new tasks if
        # not backed off stopping looping if cache becomes full
        dont_nnt = None
        if dev_loop:
            project_loop = DEV_PROJECT_WEIGHTS
            # Re-up suspend on main client
            timeout = make_discrepancy_timeout(discrepancy)
            _ = (
                await run_rpc_command(
                    client_rpc_client,
                    "set_run_mode",
                    "never",
                    str(timeout * 60 * 60 * 10),
                ),
                await run_rpc_command(
                    client_rpc_client,
                    "set_gpu_mode",
                    "never",
                    str(timeout * 60 * 60 * 10),
                ),
            )

        else:
            project_loop = highest_priority_projects
        for highest_priority_project in project_loop:
            if highest_priority_project in IGNORED_PROJECTS:
                log.debug(
                    "Skipping project bc in ignore list: {}".format(
                        highest_priority_project
                    )
                )
                continue
            boincified_url = resolve_url_boinc_rpc(
                highest_priority_project,
                dev_mode=dev_loop,
                known_attached_projects=ATTACHED_PROJECT_SET,
                known_attached_projects_dev=ATTACHED_PROJECT_SET_DEV,
                known_boinc_projects=ALL_PROJECT_URLS,
            )
            database_url = resolve_url_database(highest_priority_project)
            benchmark_result = benchmark_check(
                project_url=database_url,
                combined_stats=COMBINED_STATS,
                benchmarking_minimum_wus=BENCHMARKING_MINIMUM_WUS,
                benchmarking_minimum_time=BENCHMARKING_MINIMUM_TIME,
                benchmarking_delay_in_days=BENCHMARKING_DELAY_IN_DAYS,
                skip_benchmarking=SKIP_BENCHMARKING,
            )
            profitability_result = profitability_check(
                grc_price=grc_price * currency_rate,
                exchange_fee=EXCHANGE_FEE,
                grc_sell_price=GRC_SELL_PRICE,
                project=highest_priority_project,
                min_profit_per_hour=MIN_PROFIT_PER_HOUR,
                combined_stats=COMBINED_STATS,
            )
            if (
                ONLY_BOINC_IF_PROFITABLE
                and not benchmark_result
                and not profitability_result
                and not dev_loop
            ):
                DATABASE["TABLE_STATUS"] = "No fetch for {} bc not profitable".format(
                    database_url
                )
                update_table(dev_loop=dev_loop)
                log.info(
                    "Skipping work fetch for {} bc not profitable and ONLY_BOINC_IF_PROFITABLE is set to true".format(
                        database_url
                    )
                )
                continue
            # If user has set to only mine highest mag project if profitable and
            # it's not profitable or in benchmarking mode, skip
            if (
                ONLY_MINE_IF_PROFITABLE
                and not benchmark_result
                and not profitability_result
                and not dev_loop
                and database_url not in PREFERRED_PROJECTS
            ):
                DATABASE["TABLE_STATUS"] = (
                    "Skipping work fetch for {} bc not profitable and ONLY_MINE_IF_PROFITABLE set to true".format(
                        database_url
                    )
                )
                update_table(dev_loop=dev_loop)
                log.info(
                    "Skipping work fetch for {} bc not profitable and ONLY_MINE_IF_PROFITABLE set to true".format(
                        database_url
                    )
                )
                continue
            if database_url not in DATABASE[mode]:
                DATABASE[mode][database_url] = {}
            # Skip checking project if we have a backoff counter going and it
            # hasn't been long enough
            last_project_check: datetime.datetime = DATABASE[mode][database_url].get(
                "LAST_CHECKED", datetime.datetime(1997, 6, 21, 18, 25, 30)
            )
            backoff_period = DATABASE[mode].get(database_url, {}).get("BACKOFF", 0)
            time_since_last_project_check = datetime.datetime.now() - last_project_check
            minutes_since_last_project_check = (
                abs(time_since_last_project_check.total_seconds()) / 60
            )
            if minutes_since_last_project_check < backoff_period:
                DATABASE["TABLE_STATUS"] = (
                    "Skipping {} due to backoff period...".format(
                        highest_priority_project
                    )
                )
                update_table(dev_loop=dev_loop)
                log.debug(
                    "Skipping project {} due to backoff period... minutes_since is {} backoff period is {} last check was".format(
                        database_url,
                        minutes_since_last_project_check,
                        backoff_period,
                        last_project_check,
                    )
                )
                continue
            DATABASE["TABLE_STATUS"] = "Waiting for xfers to complete.."
            update_table(dev_loop=dev_loop)
            log.info("Waiting for any xfers to complete...")
            dl_response = await wait_till_no_xfers(
                rpc_client=rpc_client
            )  # Wait until all network activity has concluded
            if not dl_response:
                log.info("Timeout waiting for xfers to complete, proceeding anyway")
            # If in dev_loop, attach to project if needed
            if dev_loop:
                get_project_list = await run_rpc_command(
                    rpc_client, "get_project_status"
                )

                # On first run, there is no project list
                if isinstance(get_project_list, list):
                    # Convert to simple list of strings so we can check if
                    # project URL is in list
                    converted_project_list = project_list_to_project_list(
                        get_project_list
                    )
                else:
                    log.warning(
                        "Dev BOINC shows empty project list, this is normal on first run"
                    )
                    converted_project_list = []

                if (
                    resolve_url_boinc_rpc(
                        highest_priority_project,
                        dev_mode=dev_loop,
                        known_attached_projects=ATTACHED_PROJECT_SET,
                        known_attached_projects_dev=ATTACHED_PROJECT_SET_DEV,
                        known_boinc_projects=ALL_PROJECT_URLS,
                    )
                    not in converted_project_list
                ):
                    # Yoyo will never be in project dict due to not supporting weak auth
                    converted_dev_project_url = resolve_url_boinc_rpc(
                        highest_priority_project,
                        dev_mode=dev_loop,
                        known_attached_projects=ATTACHED_PROJECT_SET,
                        known_attached_projects_dev=ATTACHED_PROJECT_SET_DEV,
                        known_boinc_projects=ALL_PROJECT_URLS,
                    )
                    if database_url not in DEV_PROJECT_DICT:
                        if "YOYO" not in database_url:
                            log.error(
                                "Unable to attach dev account to {} bc not in DEV_PROJECT_DICT".format(
                                    database_url
                                )
                            )
                        continue
                    else:
                        log.info("Attaching dev account to {}".format(boincified_url))
                        attach_response = await run_rpc_command(
                            rpc_client,
                            "project_attach",
                            arg1="project_url",
                            arg1_val=boincified_url,
                            arg2="authenticator",
                            arg2_val=DEV_PROJECT_DICT[database_url],
                        )  # Update project
                        await asyncio.sleep(60)  # give it a chance to finish attaching
                        (
                            temp_project_list,
                            BOINC_PROJECT_NAMES,
                        ) = await get_attached_projects(
                            rpc_client
                        )  # We need to re-fetch this as it's now changed
                        ATTACHED_PROJECT_SET.update(temp_project_list)
                        boincified_url = resolve_url_boinc_rpc(
                            highest_priority_project,
                            dev_mode=dev_loop,
                            known_attached_projects=ATTACHED_PROJECT_SET,
                            known_attached_projects_dev=ATTACHED_PROJECT_SET_DEV,
                            known_boinc_projects=ALL_PROJECT_URLS,
                        )  # This may have changed, so check
                        if (
                            len(ATTACHED_PROJECT_SET) == 0
                        ):  # Using this as a proxy for "failed attach"
                            log.error(
                                "Appears to fail to attach to {}".format(boincified_url)
                            )
                            continue
                        print("")
            project_name = ALL_BOINC_PROJECTS[boincified_url]
            DATABASE["TABLE_STATUS"] = "Allowing new tasks & updating {}".format(
                project_name
            )
            log.info(
                "Allowing new tasks and updating {}".format(highest_priority_project)
            )
            update_table(dev_loop=dev_loop)
            allow_response = await run_rpc_command(
                rpc_client, "project_allowmorework", "project_url", boincified_url
            )
            update_response = await run_rpc_command(
                rpc_client, "project_update", "project_url", boincified_url
            )  # Update project
            log.debug("Requesting work from {}".format(boincified_url))
            log.debug(
                "Update response is {}".format(update_response)
            )  # added to debug no new tasks bug
            # Give BOINC time to update w project, I don't know a less hacky way to
            # do this, suggestions are welcome
            await asyncio.sleep(15)
            DATABASE[mode][database_url]["LAST_CHECKED"] = datetime.datetime.now()
            # Check if project should be backed off. If so, back it off.
            # This is an exponentially increasing backoff with a maximum time of 1 day
            # Projects are backed off if they request it, if they are
            # unresponsive/down, or if no work is available
            backoff_response = await check_log_entries_for_backoff(
                rpc_client, project_name=project_name
            )
            if backoff_response:
                if DATABASE[mode][database_url].get("BACKOFF"):
                    DATABASE[mode][database_url]["BACKOFF"] = min(
                        DATABASE[mode][database_url]["BACKOFF"] * 2, 1440
                    )
                else:
                    DATABASE[mode][database_url]["BACKOFF"] = MIN_RECHECK_TIME
            else:
                DATABASE[mode][database_url]["BACKOFF"] = 0
                log.debug("Waiting for any xfers to complete...")
                dl_response = await wait_till_no_xfers(
                    rpc_client
                )  # Wait until all network activity has concluded
                if not dl_response:
                    log.info("Timeout waiting for xfers to complete, proceeding anyway")

            # Re-NNT all projects
            nnt_response = await nnt_all_projects(rpc_client)  # NNT all projects

            # Check logs to see if both work caches are full
            cache_full = await check_log_entries(rpc_client, project_name=project_name)
            log.debug("checking log response for work cache status....")

            # If BOINC job cache is full, stop asking projects for work
            if cache_full:
                DATABASE["TABLE_SLEEP_REASON"] = "BOINC work cache full..."
                update_table(dev_loop=dev_loop)
                break

        # Allow highest priority project to be non-NNTd.
        # This enables BOINC to fetch work if it's needed before our
        # sleep period elapses
        dont_nnt = resolve_url_database(project_loop[0])
        allow_this_project = resolve_url_boinc_rpc(
            dont_nnt,
            dev_mode=dev_loop,
            known_attached_projects=ATTACHED_PROJECT_SET,
            known_attached_projects_dev=ATTACHED_PROJECT_SET_DEV,
            known_boinc_projects=ALL_PROJECT_URLS,
        )
        allow_response = await run_rpc_command(
            rpc_client, "project_allowmorework", "project_url", allow_this_project
        )
        # There's no reason to loop through all projects too often.
        await custom_sleep(CYCLE_SLEEP_TIME, rpc_client, dev_loop=dev_loop)


def main():
    global DATABASE
    global ALL_PROJECT_URLS
    global ALL_BOINC_PROJECTS
    global COMBINED_STATS
    global APPROVED_PROJECT_URLS
    global ATTACHED_PROJECT_SET
    global BOINC_PROJECT_NAMES
    global MAG_RATIOS
    global MAG_RATIO_SOURCE
    global CHECK_SIDESTAKE_RESULTS
    global DEV_PROJECT_WEIGHTS
    global FINAL_PROJECT_WEIGHTS
    global total_preferred_weight
    global priority_results
    global override_path
    global override_dest_path
    global grc_client

    global BOINC_PASSWORD

    wallet_running = True  # Switches to false if we have issues connecting

    # Verify we are in appropriate python environment
    python_major = sys.version_info.major
    python_minor = sys.version_info.minor
    if python_major < 3:
        print(
            "Error: This program requires python 3.8 or higher to run, you are running it as Python {}".format(
                platform.python_version()
            )
        )
        if not SCRIPTED_RUN:
            input("Press enter to exit")
        sys.exit(1)
    elif python_major == 3 and python_minor < 8:
        print(
            "Error: This program requires python 3.8 or higher to run, you are running it as Python {}".format(
                platform.python_version()
            )
        )
        if not SCRIPTED_RUN:
            input("Some things may not work as expected. Press enter to continue")
        else:
            print("Some things may not work as expected. Press enter to continue")
    del python_minor
    del python_major
    log.debug("Python version {}".format(platform.python_version()))
    # These must be declared early in case the user ctrl+Cs the script.
    # This way, safe_exit can use these paths
    override_path = os.path.join(BOINC_DATA_DIR, "global_prefs_override.xml")
    override_dest_path = os.path.join(os.getcwd(), "global_prefs_override_backup.xml")

    # Shut down dev client is it's running. This is useful if program shuts
    # down unexpectedly
    shutdown_dev_client(quiet=True)

    # Load long-term stats
    if os.path.exists(STAT_FILE):
        try:
            with open(STAT_FILE) as json_file:
                DATABASE = json.load(json_file, object_hook=object_hook)
        except Exception as e:
            if os.path.exists("{}.backup".format(STAT_FILE)):
                print("Error opening stats file, trying backup...")
                log.error("Error opening stats file, trying backup...")
                try:
                    with open("{}.backup".format(STAT_FILE)) as json_file:
                        DATABASE = json.load(json_file, object_hook=object_hook)
                except:
                    print_and_log(
                        "Error opening stats file, making new one...", "ERROR"
                    )
                    DATABASE = create_default_database()
                    save_stats(DATABASE)
            else:
                print_and_log("Error loading stats file. Making new one...", "ERROR")
                shutil.copy(STAT_FILE, "{}.corrupted".format(STAT_FILE))
                DATABASE = create_default_database()
                save_stats(DATABASE)
    else:
        log.warning("No stats file found, making new one...")
        DATABASE = create_default_database()
        save_stats(DATABASE)

    # These vars should reset and/or checked each run
    DATABASE["TABLE_STATUS"] = ""
    DATABASE["TABLE_SLEEP_REASON"] = ""
    if "FTMTOTAL" not in DATABASE:
        DATABASE["FTMTOTAL"] = 0
    if "DEVTIMETOTAL" not in DATABASE:
        DATABASE["DEVTIMETOTAL"] = 0

    with GracefulInterruptHandler(
        [signal.SIGINT, signal.SIGTERM], safe_exit
    ) as h:  # Capture ctrl+c from client to exit gracefully
        update_check()  # Check for updates to FTM
        COMBINED_STATS = {}
        APPROVED_PROJECT_URLS = []
        # COMBINED_STATS has format:
        #    COMBINED_STATS_EXAMPLE = {
        #        'HTTP://PROJECT.COM/PROJECT': {
        #            'COMPILED_STATS': {
        #                'AVGWALLTIME': 30.01, 'AVGCPUTIME': 10.02, 'TOTALTASKS': 51, 'TOTALWALLTIME': 223311.34,
        #                'AVGCREDITPERHOUR': 31.2, 'XDAYWALLTIME': 30, 'AVGCREDITPERTASK': 32.12, 'AVGMAGPERHOUR': 32.1, 'TOTALCPUTIME':300010.10},
        #            'CREDIT_HISTORY': {
        #                '11-29-21': {'CREDITAWARDED':100.54},
        #                '11-28-21': {'CREDITAWARDED':100.21},
        #            },
        #            'WU_HISTORY': {
        #                '07-31-2021':{'STARTTIME': '1627765997', 'ESTTIME': '6128.136145', 'CPUTIME': '3621.724000',
        #                 'ESTIMATEDFLOPS': '30000000000000', 'TASKNAME': 'wu_sf3_DS-16x271-9_Grp218448of1000000_0',
        #                 'WALLTIME': '3643.133927', 'EXITCODE': '0'},
        #                '07-29-2021': {'STARTTIME': '1627765996', 'ESTTIME': '6128.136145', 'CPUTIME': '3621.724000',
        #                               'ESTIMATEDFLOPS': '30000000000000',
        #                               'TASKNAME': 'wu_sf3_DS-16x271-9_Grp218448of1000000_0',
        #                               'WALLTIME': '3643.133927', 'EXITCODE': '0'},
        #            }
        #        },
        #    }

        # Check that directories exist
        log.info("Guessing BOINC data dir is " + str(BOINC_DATA_DIR))
        if not os.path.isdir(BOINC_DATA_DIR):
            print_and_log(
                "BOINC data dir does not appear to exist. If you have it in a non-standard location, please edit config.py so we know where to look",
                "ERROR",
            )
            if not SCRIPTED_RUN:
                input("Press enter to exit")
            sys.exit(1)
        log.info("Guessing Gridcoin data dir is " + str(GRIDCOIN_DATA_DIR))
        if not os.path.isdir(GRIDCOIN_DATA_DIR):
            print_and_log(
                "Gridcoin data dir does not appear to exist. If you have it in a non-standard location, please edit config.py so we know where to look",
                "ERROR",
            )
            if not SCRIPTED_RUN:
                input("Press enter to continue or CTRL+C to quit")
            wallet_running = False

        try:
            os.access(override_path, os.W_OK)
        except Exception as e:
            print_and_log(
                "This program does not have write access to your BOINC config file, meaning it can't reset settings back to your original ones upon close",
                "ERROR",
            )
            print_and_log(
                "Linux users try 'sudo chown your_username {}' to fix this error".format(
                    override_path
                ),
                "INFO",
            )
            if not SCRIPTED_RUN:
                input("Press enter to continue")

        # Auto-detect password for BOINC RPC if it exists and user didn't know
        # BOINC on Windows automatically generates an RPC password
        auth_location = os.path.join(BOINC_DATA_DIR, "gui_rpc_auth.cfg")
        if not BOINC_PASSWORD:
            try:
                with open(auth_location, "r") as file:
                    data = file.read().rstrip()
                    if data != "":
                        BOINC_PASSWORD = data
            except Exception as e:
                # This error can generally be disregarded on Linux/OSX
                if "WINDOWS" in FOUND_PLATFORM.upper():
                    print(
                        "Error reading boinc RPC file at {}: {}".format(
                            auth_location, e
                        )
                    )
                    log.error(
                        "Error reading boinc RPC file at {}: {}".format(
                            auth_location, e
                        )
                    )
                else:
                    log.debug(
                        "Error reading boinc RPC file at {}: {}".format(
                            auth_location, e
                        )
                    )

        # Check that project weights make sense
        total_found_values = 0
        for url, found_value in PREFERRED_PROJECTS.items():
            total_found_values += found_value
        if total_found_values != 100 and len(PREFERRED_PROJECTS) > 0:
            print_and_log(
                "Warning: The weights of your preferred projects do not add up to 100! Quitting.",
                "ERROR",
            )
            if not SCRIPTED_RUN:
                input("Press enter to exit")
            sys.exit(1)

        # Establish connections to BOINC and Gridcoin clients, get basic info
        boinc_client = None
        grc_client = None
        gridcoin_conf = None
        try:
            boinc_client = BoincClientConnection(config_dir=BOINC_DATA_DIR)
        except Exception as e:
            print_and_log(
                "Unable to open BOINC data directory. You may need to specify location in config. Error "
                + str(e),
                "ERROR",
            )
            if not SCRIPTED_RUN:
                input("Press enter to exit")
            sys.exit(1)
        if wallet_running:
            try:
                gridcoin_conf = get_gridcoin_config_parameters(GRIDCOIN_DATA_DIR)
            except Exception as e:
                print(
                    "Error parsing gridcoin config file in directory: "
                    + GRIDCOIN_DATA_DIR
                    + " Error: "
                    + str(e)
                )
                log.error(
                    "Error parsing gridcoin config file in directory: "
                    + GRIDCOIN_DATA_DIR
                    + " Error: "
                    + str(e)
                )
                wallet_running = False
                rpc_user = None
                gridcoin_rpc_password = None
                rpc_port = None
            else:
                # Set Gridcoin login parameters for use later
                rpc_user = gridcoin_conf.get("rpcuser")
                gridcoin_rpc_password = gridcoin_conf.get("rpcpassword")
                rpc_port = gridcoin_conf.get("rpcport")
            if not rpc_user or not gridcoin_rpc_password or not rpc_port:
                print(
                    "Error: Gridcoin wallet is not configured to accept RPC commands based on config file from "
                    + str(GRIDCOIN_DATA_DIR)
                )
                log.error(
                    "Error: Gridcoin wallet is not configured to accept RPC commands based on config file from "
                    + str(GRIDCOIN_DATA_DIR)
                )
                print(
                    "RPC commands enable us to talk to the Gridcoin client and get information about project magnitude ratios"
                )
                if not SCRIPTED_RUN:
                    print(
                        "Would you like us to automatically configure your Gridcoin client to accept RPC commands?"
                    )
                    print(
                        "It will be configured to only accept commands from your machine."
                    )
                    print(
                        "If you do not enable this, this script can only update its information about project magnitudes once a day through an external website"
                    )
                    print("This can cause inefficient crunching and is not advised")
                    print(
                        'Please answer "Y" or "N" without quotes. Then press the enter key'
                    )
                    answer = input("")
                    log.debug("User input: " + answer)
                    while answer not in ["Y", "N", "y", "n"]:
                        print("Error: Y or N not entered. Try again please :)")
                        answer = input("")
                    if answer == "N" or answer == "n":
                        print("Ok, we won't")
                    elif answer == "Y" or answer == "y":
                        with open(
                            os.path.join(GRIDCOIN_DATA_DIR, "gridcoinresearch.conf"),
                            "a",
                        ) as myfile:
                            from random import choice
                            from string import ascii_uppercase
                            from string import ascii_lowercase
                            from string import digits

                            rpc_user = "".join(
                                choice(ascii_uppercase) for i in range(8)
                            )
                            gridcoin_rpc_password = "".join(
                                choice(ascii_uppercase + ascii_lowercase + digits)
                                for i in range(12)
                            )
                            rpc_port = "9876"
                            print("Your RPC username is: " + rpc_user)
                            print("Your RPC password is: " + gridcoin_rpc_password)
                            print("You don't need to remember these.")
                            print("Modifying config file...")
                            myfile.write("rpcport=9876\n")
                            myfile.write("server=1\n")
                            myfile.write("rpcuser=" + rpc_user + "\n")
                            myfile.write("rpcpassword=" + gridcoin_rpc_password + "\n")
                        print(
                            "Alright, we've modified the config file. Please restart the gridcoin wallet."
                        )
                        print(
                            "Once it's loaded and --fully-- synced, press enter to continue"
                        )
                        input("")
        else:
            rpc_user = None
            gridcoin_rpc_password = None
            rpc_port = None

        # Get project list from BOINC
        rpc_client = None
        try:
            rpc_client = loop.run_until_complete(
                setup_connection(BOINC_IP, BOINC_PASSWORD, BOINC_PORT)
            )  # Setup BOINC RPC connection
        except Exception as e:
            print_and_log(
                "Error: Unable to connect to BOINC client, quitting now", "ERROR"
            )
            sys.exit(1)
        if not rpc_client:
            print_and_log(
                "Error: Unable to connect to BOINC client, quitting now", "ERROR"
            )
            sys.exit(1)
        # Get project list from BOINC client directly. This is needed for
        # correct capitalization
        temp_project_set, temp_project_names = loop.run_until_complete(
            get_attached_projects(rpc_client)
        )
        if not temp_project_set or not temp_project_names:
            print_and_log(
                "Error connecting to BOINC client, unable to get project list.", "ERROR"
            )
            sys.exit(1)
        ATTACHED_PROJECT_SET.update(temp_project_set)
        combine_dicts(BOINC_PROJECT_NAMES, temp_project_names)
        try:
            ALL_BOINC_PROJECTS = loop.run_until_complete(get_all_projects(rpc_client))
        except Exception as e:
            print("Error communicating with BOINC client, exiting")
            safe_exit(None, None)

        # Get project list from Gridcoin wallet and/or gridcoinstats, check sidestakes
        foundation_address = "bc3NA8e8E3EoTL1qhRmeprbjWcmuoZ26A2"
        developer_address = "RzUgcntbFm8PeSJpauk6a44qbtu92dpw3K"
        try:
            grc_client = GridcoinClientConnection(
                rpc_user=rpc_user, rpc_port=rpc_port, rpc_password=gridcoin_rpc_password
            )
            # Test if the client is connectable
            source_urls = grc_client.get_approved_project_urls()
            wait_till_synced(grc_client)
            source_urls = grc_client.get_approved_project_urls()
            log.debug("Got source_urls from wallet: {}".format(source_urls))
            APPROVED_PROJECT_URLS = resolve_url_list_to_database(source_urls)
            log.debug("Got APPROVED from wallet: {}".format(APPROVED_PROJECT_URLS))
            MAG_RATIOS = ProjectMagRatio.get_project_mag_ratios(
                grc_client,
                LOOKBACK_PERIOD,
                dump_rac_mag_ratios=(
                    (lambda d: save_stats(d, "RAC_MAG_RATIOS"))
                    if DUMP_RAC_MAG_RATIOS
                    else None
                ),
            )
            DATABASE["MAGLASTCHECKED"] = datetime.datetime.now()
            log.debug("Got MAG_RATIOS from wallet at startup: {}".format(MAG_RATIOS))
            if not MAG_RATIOS:
                raise ConnectionError("Issues connecting with Gridcoin wallet")
        except Exception as e:
            MAG_RATIO_SOURCE = "WEB"
            print_and_log(
                "Unable to connect to Gridcoin wallet. Assuming it doesn't exist. Error: ",
                "ERROR",
            )
            log.error("{}".format(e))
            print(
                "It is suggested to install the Gridcoin wallet for the most up-to-date magnitude information"
            )
            print(
                "Otherwise, we will fetch data from gridcoinstats.eu which is limited to once per day"
            )
            log.warning(
                "Unable to connect to gridcoin wallet! {} Trying web-based option...".format(
                    e
                )
            )
            wallet_running = False
            if STRICT_GRIDCOIN:
                if not SCRIPTED_RUN:
                    print("Press enter to exit")
                sys.exit(1)
            try:
                project_resolver_dict = get_approved_project_urls_web()
                APPROVED_PROJECT_URLS = resolve_url_list_to_database(
                    list(project_resolver_dict.values())
                )
                MAG_RATIOS = ProjectMagRatio.get_project_mag_ratios_from_url(
                    project_resolver_dict=project_resolver_dict,
                    dump_rac_mag_ratios=(
                        (lambda d: save_stats(d, "RAC_MAG_RATIOS"))
                        if DUMP_RAC_MAG_RATIOS
                        else None
                    ),
                    proxies=EXTERNAL_REQUEST_PROXIES,
                )
                DATABASE["MAGLASTCHECKED"] = datetime.datetime.now()
                log.debug("Got MAG_RATIOS from web at startup: {}".format(MAG_RATIOS))
            except Exception as e:
                print_and_log(
                    "Error getting project URL list from URL. Are you sure it's open? Error: "
                    + str(e),
                    "ERROR",
                )
                if not SCRIPTED_RUN:
                    input("Press enter to exit")
                sys.exit(1)
        else:
            assert gridcoin_conf is not None
            MAG_RATIO_SOURCE = "WALLET"
            # Check sidestakes, prompt user to enable them if they don't exist
            CHECK_SIDESTAKE_RESULTS = check_sidestake(
                gridcoin_conf, foundation_address, 1
            )
            if not SCRIPTED_RUN and not CHECK_SIDESTAKE_RESULTS:
                sidestake_prompt(
                    CHECK_SIDESTAKE_RESULTS, "FOUNDATION", foundation_address
                )
            CHECK_SIDESTAKE_RESULTS = check_sidestake(
                gridcoin_conf, developer_address, 1
            )
            if not SCRIPTED_RUN and not CHECK_SIDESTAKE_RESULTS:
                sidestake_prompt(
                    CHECK_SIDESTAKE_RESULTS, "DEVELOPER", developer_address
                )
            print(
                "Welcome to FindTheMag and thank you for trying out this tool. Your feedback and suggestions are welcome on the github page : )"
            )
            CHECK_SIDESTAKE_RESULTS = check_sidestake(
                gridcoin_conf, developer_address, 1
            )
            if CHECK_SIDESTAKE_RESULTS:
                DEV_FEE_MODE = "SIDESTAKE"

        # Get project list from BOINC
        try:
            ALL_PROJECT_URLS = boinc_client.get_project_list()
        except Exception as e:
            print_and_log(
                "Error getting project URL list from BOINC " + str(e), "ERROR"
            )

        (
            COMBINED_STATS,
            FINAL_PROJECT_WEIGHTS,
            total_preferred_weight,
            total_mining_weight,
            DEV_PROJECT_WEIGHTS,
        ) = generate_stats(
            combined_stats=config_files_to_stats(
                BOINC_DATA_DIR, rolling_weight_window=ROLLING_WEIGHT_WINDOW
            ),
            approved_project_urls=APPROVED_PROJECT_URLS,
            preferred_projects=PREFERRED_PROJECTS,
            ignored_projects=IGNORED_PROJECTS,
            quiet=False,
            mag_ratios=MAG_RATIOS,
        )
        log.debug("Printing pretty stats...")
        # Calculate starting efficiency stats
        if "STARTMAGHR" not in DATABASE:
            DATABASE["STARTMAGHR"] = get_avg_mag_hr(COMBINED_STATS)
        else:
            original_avg_mag_hr = DATABASE["STARTMAGHR"]
            current_avg_mag_hr = get_avg_mag_hr(COMBINED_STATS)
        # Generate table to print pretty
        table_dict = {}
        for project_url, stats_dict in COMBINED_STATS.items():
            table_dict[project_url] = {}
            for stat_name, stat_value in stats_dict["COMPILED_STATS"].items():
                rounding = 2
                if stat_name == "MAGPERCREDIT":
                    rounding = 5
                table_dict[project_url][stat_name] = str(
                    round(float(stat_value), rounding)
                )
        print("")
        if len(table_dict) > 0:
            print("SOME PRETTY STATS JUST FOR YOU, SORTED BY AVG GRC/DAY")
            priority_results = {}
            update_table(clear=False)
            del priority_results  # this is only created temporarily as update_table expects it
        else:
            print(
                "Not enough stats to print a table of them yet, guessing this is a new BOINC install?"
            )
        print(
            "Total project weight will be 1000. We will reserve a minimum .01% of processing power for monitoring each project"
        )
        print_and_log(
            "Total weight for preferred projects is "
            + str(round(float(total_preferred_weight), 2)),
            "INFO",
        )
        print_and_log(
            "Total weight for mining projects is "
            + str(round(float(total_mining_weight), 2)),
            "INFO",
        )
        print_and_log("FINAL SUGGESTED PROJECT WEIGHTS", "INFO")
        for project, weight in FINAL_PROJECT_WEIGHTS.items():
            print_and_log(project.lower() + ": " + str(weight), "INFO")
        if CHECK_SIDESTAKE_RESULTS:
            print(
                "~~---***Wow THANK YOU for sidestaking to our development. You rock!***---~~~"
            )
            print("Yeeeehaw! We're going to the pony store!")
            print(
                "This also means 100% of the crunching time on this machine will be under your account, no need to crunch for developer"
            )
            print(
                r"""
---             ,--,
----      _ ___/ /\|
-----    ;( )__, )
-----   ; //   '--;
----      \     |
---        v    v"""
            )
        else:
            print(
                "If you'd like to say thank you to the developers of this tool, please help us buy our next round of energy drinks by sending GRC to:"
            )
            print(developer_address)
        if not CONTROL_BOINC and not SCRIPTED_RUN:
            input("Press enter key or CTRL+C to quit")
            sys.exit()
        else:
            if not SCRIPTED_RUN:
                print(
                    "Press enter key to start controlling BOINC. Press Ctrl+C to quit"
                )
        if not SCRIPTED_RUN:
            answer = input("")
        print_and_log("Starting control of BOINC...", "DEBUG")
        if "DARWIN" in FOUND_PLATFORM.upper() and not CHECK_SIDESTAKE_RESULTS:
            print_and_log(
                'Sidestaking must be setup for BOINC control on OS X as "crunch for dev" is not an option. Re-run the script to set this up.',
                "ERROR",
            )
            sys.exit(1)

        # Backup user preferences.
        try:
            shutil.copy(override_path, override_dest_path)
        except Exception as e:
            log.warning(
                "global_prefs_override.xml does not appear to exist, not backing up. Some users may not have one. Error: {}".format(
                    e
                )
            )
            try:
                os.remove(override_dest_path)
            except Exception as e:
                log.info(
                    "global_prefs_override_backup.xml does not appear to exist. This is expected. Error: {}".format(
                        e
                    )
                )

        verification_result = loop.run_until_complete(
            verify_boinc_connection(rpc_client)
        )
        if not verification_result:
            print_and_log(
                "Error connecting to BOINC client, does your gui_rpc_auth.cfg specify a password or a non-standard port?\n If so, be sure to include it in your config.py",
                "ERROR",
            )
            print("You can find your gui_rpc_auth.cfg at {}".format(auth_location))
            print(
                "Linux users: make sure your username is in the BOINC group so FTM can access your BOINC config file"
            )
            print("sudo usermod -aG boinc your_username_here")
            print(
                "Note that you will need to restart your computer after changing your group permissions"
            )
            if not SCRIPTED_RUN:
                answer = input("Press enter to quit")
            sys.exit(1)
        try:
            loop.run_until_complete(
                prefs_check(
                    rpc_client,
                    min_gb=MIN_GB,
                    expected_gb_used=EXPECTED_GB_USED,
                    scripted_run=SCRIPTED_RUN,
                    testing=TESTING,
                )
            )
        except Exception as e:
            print_and_log(
                "Error connecting to BOINC for prefs_check. Is BOINC running?", "ERROR"
            )
            sys.exit(1)
        # NNT all projects
        nnt_response = loop.run_until_complete(nnt_all_projects(rpc_client))
        # Abort unstarted tasks if the user requested it
        if ABORT_UNSTARTED_TASKS:
            loop.run_until_complete(kill_all_unstarted_tasks(rpc_client))
        priority_results = {}
        # Force calculation of stats at first run since they are not cached in DB
        DATABASE["STATSLASTCALCULATED"] = datetime.datetime(1997, 3, 3)
        # While we don't have enough tasks, continue cycling through project list and
        # updating. If we have cycled through all projects, get_highest_priority_project
        # will stall to prevent requesting too often
        loop.run_until_complete(boinc_loop(False, rpc_client))
    # Restore user prefs
    safe_exit(None, None)


if __name__ == "__main__":
    main()
